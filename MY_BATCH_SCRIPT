#!/bin/bash


#SBATCH --job-name=test #Assign a descriptive job name

#SBATCH -N 1                    # Request 1 node
#SBATCH --mem=200G               # Request 400GB memory
#SBATCH -t 130:50:00             # Set maximum time

#SBATCH --gres=gpu:nvidia_a100_80:2
#SBATCH --partition=tier2_gpu
#SBATCH --account=aristeidis_sotiras

##SBATCH --array=0-7              # Array of 8 tasks (0 to 7)

# Output and error filenames based on job ID and task ID
#SBATCH --output=slurm-%A_%a.out 
#SBATCH --error=slurm-%A_%a.err 

module load python
module load cuda/11.3
module load cudnn/8.1.1

source ~/liuenv/bin/activate
pip install torchvision

#python ViT_dm_mri.py
#python keras_u-net_dm_mri.py
#python cbam_cd_mri.py
#python cbam_full_cd_mri.py
#python cbam_sin_dm_mri.py
python GAN.py
# List of Python scripts you want to run (internal array)
#scripts=("deep_learning_cd_MRI.py" "deep_learning_cd_PET.py" "deep_learning_cm_MRI.py" "deep_learning_cm_PET.py" "deep_learning_dm_MRI.py" "deep_learning_dm_PET.py" "deep_learning_pc_MRI.py" "deep_learning_pc_PET.py")

# Select the Python script to run based on the SLURM_ARRAY_TASK_ID
#script=${scripts[$SLURM_ARRAY_TASK_ID]}

# Run the corresponding Python script for this task
#srun python $script
