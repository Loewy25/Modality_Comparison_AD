#!/bin/bash


#SBATCH --job-name=ke_dm_pet # Assign a descriptive job name
#SBATCH -N 1                     # Request 1 node
#SBATCH --mem=80G               # Request 400GB memory
#SBATCH -t 130:50:00             # Set maximum time
#SBATCH --gres=gpu:1     # Request 4 GPUs
#SBATCH --partition=tier2_gpu
#SBATCH --nodelist=gpu02,gpu03,gpa[401-410],gpua[801-805],gpuh[801-802],gpugh01  # Specify the high-memory, advanced GPU nodes
#SBATCH --account=aristeidis_sotiras

##SBATCH --array=0-7              # Array of 8 tasks (0 to 7)

# Output and error filenames based on job ID and task ID
#SBATCH --output=slurm-%A_%a.out 
#SBATCH --error=slurm-%A_%a.err 

module load python
module load cuda/11.3
module load cudnn/8.1.1

source ~/liuenv/bin/activate
pip install torch
python keras_u-net_cd_mri.py
#python cbam_cd_mri.py
#python cbam_full_cd_pet.py
# List of Python scripts you want to run (internal array)
#scripts=("deep_learning_cd_MRI.py" "deep_learning_cd_PET.py" "deep_learning_cm_MRI.py" "deep_learning_cm_PET.py" "deep_learning_dm_MRI.py" "deep_learning_dm_PET.py" "deep_learning_pc_MRI.py" "deep_learning_pc_PET.py")

# Select the Python script to run based on the SLURM_ARRAY_TASK_ID
#script=${scripts[$SLURM_ARRAY_TASK_ID]}

# Run the corresponding Python script for this task
#srun python $script
