--------------------------------------------------------------
Begin Slurm Prologue Sun Sep 15 11:57:57 CDT 2024 1726419477
Job ID:		2044224
Username:	l.peiwang
Partition:	tier2_gpu
End Slurm Prologue Sun Sep 15 11:57:57 CDT 2024 1726419477
--------------------------------------------------------------
/home/l.peiwang/liuenv/lib/python3.10/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.
  warnings.warn(message, FutureWarning)
2024-09-15 12:04:41.437535: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-15 12:04:44.327430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38212 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:b1:00.0, compute capability: 8.0
Number of CN subjects:
263
Number of PCN subjects:
140
Number of MCI subjects:
458
Number of Dementia subjects:
151
lenth of dataset: 
414
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Original image shape: (91, 109, 91)
Zoom factors: [1.4065934065934067, 1.1743119266055047, 1.4065934065934067]
Resized image shape: (128, 128, 128)
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               
                                28, 1)]                                                           
                                                                                                  
 conv3d (Conv3D)                (None, 128, 128, 12  448         ['input_1[0][0]']                
                                8, 16)                                                            
                                                                                                  
 batch_normalization (BatchNorm  (None, 128, 128, 12  64         ['conv3d[0][0]']                 
 alization)                     8, 16)                                                            
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 128, 128, 12  0           ['batch_normalization[0][0]']    
                                8, 16)                                                            
                                                                                                  
 conv3d_1 (Conv3D)              (None, 128, 128, 12  6928        ['leaky_re_lu[0][0]']            
                                8, 16)                                                            
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 128, 128, 12  64         ['conv3d_1[0][0]']               
 rmalization)                   8, 16)                                                            
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 128, 128, 12  0           ['batch_normalization_1[0][0]']  
                                8, 16)                                                            
                                                                                                  
 spatial_dropout3d (SpatialDrop  (None, 128, 128, 12  0          ['leaky_re_lu_1[0][0]']          
 out3D)                         8, 16)                                                            
                                                                                                  
 conv3d_2 (Conv3D)              (None, 128, 128, 12  6928        ['spatial_dropout3d[0][0]']      
                                8, 16)                                                            
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 128, 128, 12  64         ['conv3d_2[0][0]']               
 rmalization)                   8, 16)                                                            
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  
                                8, 16)                                                            
                                                                                                  
 add (Add)                      (None, 128, 128, 12  0           ['leaky_re_lu_2[0][0]',          
                                8, 16)                            'leaky_re_lu[0][0]']            
                                                                                                  
 conv3d_3 (Conv3D)              (None, 64, 64, 64,   13856       ['add[0][0]']                    
                                32)                                                               
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 64, 64, 64,   128        ['conv3d_3[0][0]']               
 rmalization)                   32)                                                               
                                                                                                  
 leaky_re_lu_3 (LeakyReLU)      (None, 64, 64, 64,   0           ['batch_normalization_3[0][0]']  
                                32)                                                               
                                                                                                  
 conv3d_4 (Conv3D)              (None, 64, 64, 64,   27680       ['leaky_re_lu_3[0][0]']          
                                32)                                                               
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 64, 64, 64,   128        ['conv3d_4[0][0]']               
 rmalization)                   32)                                                               
                                                                                                  
 leaky_re_lu_4 (LeakyReLU)      (None, 64, 64, 64,   0           ['batch_normalization_4[0][0]']  
                                32)                                                               
                                                                                                  
 spatial_dropout3d_1 (SpatialDr  (None, 64, 64, 64,   0          ['leaky_re_lu_4[0][0]']          
 opout3D)                       32)                                                               
                                                                                                  
 conv3d_5 (Conv3D)              (None, 64, 64, 64,   27680       ['spatial_dropout3d_1[0][0]']    
                                32)                                                               
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 64, 64, 64,   128        ['conv3d_5[0][0]']               
 rmalization)                   32)                                                               
                                                                                                  
 leaky_re_lu_5 (LeakyReLU)      (None, 64, 64, 64,   0           ['batch_normalization_5[0][0]']  
                                32)                                                               
                                                                                                  
 add_1 (Add)                    (None, 64, 64, 64,   0           ['leaky_re_lu_5[0][0]',          
                                32)                               'leaky_re_lu_3[0][0]']          
                                                                                                  
 conv3d_6 (Conv3D)              (None, 32, 32, 32,   55360       ['add_1[0][0]']                  
                                64)                                                               
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 32, 32, 32,   256        ['conv3d_6[0][0]']               
 rmalization)                   64)                                                               
                                                                                                  
 leaky_re_lu_6 (LeakyReLU)      (None, 32, 32, 32,   0           ['batch_normalization_6[0][0]']  
                                64)                                                               
                                                                                                  
 conv3d_7 (Conv3D)              (None, 32, 32, 32,   110656      ['leaky_re_lu_6[0][0]']          
                                64)                                                               
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 32, 32, 32,   256        ['conv3d_7[0][0]']               
 rmalization)                   64)                                                               
                                                                                                  
 leaky_re_lu_7 (LeakyReLU)      (None, 32, 32, 32,   0           ['batch_normalization_7[0][0]']  
                                64)                                                               
                                                                                                  
 spatial_dropout3d_2 (SpatialDr  (None, 32, 32, 32,   0          ['leaky_re_lu_7[0][0]']          
 opout3D)                       64)                                                               
                                                                                                  
 conv3d_8 (Conv3D)              (None, 32, 32, 32,   110656      ['spatial_dropout3d_2[0][0]']    
                                64)                                                               
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 32, 32, 32,   256        ['conv3d_8[0][0]']               
 rmalization)                   64)                                                               
                                                                                                  
 leaky_re_lu_8 (LeakyReLU)      (None, 32, 32, 32,   0           ['batch_normalization_8[0][0]']  
                                64)                                                               
                                                                                                  
 add_2 (Add)                    (None, 32, 32, 32,   0           ['leaky_re_lu_8[0][0]',          
                                64)                               'leaky_re_lu_6[0][0]']          
                                                                                                  
 conv3d_9 (Conv3D)              (None, 16, 16, 16,   221312      ['add_2[0][0]']                  
                                128)                                                              
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 16, 16, 16,   512        ['conv3d_9[0][0]']               
 rmalization)                   128)                                                              
                                                                                                  
 leaky_re_lu_9 (LeakyReLU)      (None, 16, 16, 16,   0           ['batch_normalization_9[0][0]']  
                                128)                                                              
                                                                                                  
 conv3d_10 (Conv3D)             (None, 16, 16, 16,   442496      ['leaky_re_lu_9[0][0]']          
                                128)                                                              
                                                                                                  
 batch_normalization_10 (BatchN  (None, 16, 16, 16,   512        ['conv3d_10[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_10 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_10[0][0]'] 
                                128)                                                              
                                                                                                  
 spatial_dropout3d_3 (SpatialDr  (None, 16, 16, 16,   0          ['leaky_re_lu_10[0][0]']         
 opout3D)                       128)                                                              
                                                                                                  
 conv3d_11 (Conv3D)             (None, 16, 16, 16,   442496      ['spatial_dropout3d_3[0][0]']    
                                128)                                                              
                                                                                                  
 batch_normalization_11 (BatchN  (None, 16, 16, 16,   512        ['conv3d_11[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_11 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_11[0][0]'] 
                                128)                                                              
                                                                                                  
 add_3 (Add)                    (None, 16, 16, 16,   0           ['leaky_re_lu_11[0][0]',         
                                128)                              'leaky_re_lu_9[0][0]']          
                                                                                                  
 conv3d_12 (Conv3D)             (None, 8, 8, 8, 256  884992      ['add_3[0][0]']                  
                                )                                                                 
                                                                                                  
 batch_normalization_12 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_12[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_12 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_12[0][0]'] 
                                )                                                                 
                                                                                                  
 conv3d_13 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['leaky_re_lu_12[0][0]']         
                                )                                                                 
                                                                                                  
 batch_normalization_13 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_13[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_13 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_13[0][0]'] 
                                )                                                                 
                                                                                                  
 spatial_dropout3d_4 (SpatialDr  (None, 8, 8, 8, 256  0          ['leaky_re_lu_13[0][0]']         
 opout3D)                       )                                                                 
                                                                                                  
 conv3d_14 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['spatial_dropout3d_4[0][0]']    
                                )                                                                 
                                                                                                  
 batch_normalization_14 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_14[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_14 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_14[0][0]'] 
                                )                                                                 
                                                                                                  
 add_4 (Add)                    (None, 8, 8, 8, 256  0           ['leaky_re_lu_14[0][0]',         
                                )                                 'leaky_re_lu_12[0][0]']         
                                                                                                  
 global_average_pooling3d (Glob  (None, 256)         0           ['add_4[0][0]']                  
 alAveragePooling3D)                                                                              
                                                                                                  
 dropout (Dropout)              (None, 256)          0           ['global_average_pooling3d[0][0]'
                                                                 ]                                
                                                                                                  
 dense (Dense)                  (None, 2)            514         ['dropout[0][0]']                
                                                                                                  
==================================================================================================
Total params: 5,897,410
Trainable params: 5,894,434
Non-trainable params: 2,976
__________________________________________________________________________________________________
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               
                                28, 1)]                                                           
                                                                                                  
 conv3d_15 (Conv3D)             (None, 128, 128, 12  448         ['input_2[0][0]']                
                                8, 16)                                                            
                                                                                                  
 batch_normalization_15 (BatchN  (None, 128, 128, 12  64         ['conv3d_15[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_15 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 conv3d_16 (Conv3D)             (None, 128, 128, 12  6928        ['leaky_re_lu_15[0][0]']         
                                8, 16)                                                            
                                                                                                  
 batch_normalization_16 (BatchN  (None, 128, 128, 12  64         ['conv3d_16[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_16 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_16[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 spatial_dropout3d_5 (SpatialDr  (None, 128, 128, 12  0          ['leaky_re_lu_16[0][0]']         
 opout3D)                       8, 16)                                                            
                                                                                                  
 conv3d_17 (Conv3D)             (None, 128, 128, 12  6928        ['spatial_dropout3d_5[0][0]']    
                                8, 16)                                                            
                                                                                                  
 batch_normalization_17 (BatchN  (None, 128, 128, 12  64         ['conv3d_17[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_17 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_17[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 add_5 (Add)                    (None, 128, 128, 12  0           ['leaky_re_lu_17[0][0]',         
                                8, 16)                            'leaky_re_lu_15[0][0]']         
                                                                                                  
 conv3d_18 (Conv3D)             (None, 64, 64, 64,   13856       ['add_5[0][0]']                  
                                32)                                                               
                                                                                                  
 batch_normalization_18 (BatchN  (None, 64, 64, 64,   128        ['conv3d_18[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_18 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_18[0][0]'] 
                                32)                                                               
                                                                                                  
 conv3d_19 (Conv3D)             (None, 64, 64, 64,   27680       ['leaky_re_lu_18[0][0]']         
                                32)                                                               
                                                                                                  
 batch_normalization_19 (BatchN  (None, 64, 64, 64,   128        ['conv3d_19[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_19 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_19[0][0]'] 
                                32)                                                               
                                                                                                  
 spatial_dropout3d_6 (SpatialDr  (None, 64, 64, 64,   0          ['leaky_re_lu_19[0][0]']         
 opout3D)                       32)                                                               
                                                                                                  
 conv3d_20 (Conv3D)             (None, 64, 64, 64,   27680       ['spatial_dropout3d_6[0][0]']    
                                32)                                                               
                                                                                                  
 batch_normalization_20 (BatchN  (None, 64, 64, 64,   128        ['conv3d_20[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_20 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_20[0][0]'] 
                                32)                                                               
                                                                                                  
 add_6 (Add)                    (None, 64, 64, 64,   0           ['leaky_re_lu_20[0][0]',         
                                32)                               'leaky_re_lu_18[0][0]']         
                                                                                                  
 conv3d_21 (Conv3D)             (None, 32, 32, 32,   55360       ['add_6[0][0]']                  
                                64)                                                               
                                                                                                  
 batch_normalization_21 (BatchN  (None, 32, 32, 32,   256        ['conv3d_21[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_21 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_21[0][0]'] 
                                64)                                                               
                                                                                                  
 conv3d_22 (Conv3D)             (None, 32, 32, 32,   110656      ['leaky_re_lu_21[0][0]']         
                                64)                                                               
                                                                                                  
 batch_normalization_22 (BatchN  (None, 32, 32, 32,   256        ['conv3d_22[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_22 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_22[0][0]'] 
                                64)                                                               
                                                                                                  
 spatial_dropout3d_7 (SpatialDr  (None, 32, 32, 32,   0          ['leaky_re_lu_22[0][0]']         
 opout3D)                       64)                                                               
                                                                                                  
 conv3d_23 (Conv3D)             (None, 32, 32, 32,   110656      ['spatial_dropout3d_7[0][0]']    
                                64)                                                               
                                                                                                  
 batch_normalization_23 (BatchN  (None, 32, 32, 32,   256        ['conv3d_23[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_23 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_23[0][0]'] 
                                64)                                                               
                                                                                                  
 add_7 (Add)                    (None, 32, 32, 32,   0           ['leaky_re_lu_23[0][0]',         
                                64)                               'leaky_re_lu_21[0][0]']         
                                                                                                  
 conv3d_24 (Conv3D)             (None, 16, 16, 16,   221312      ['add_7[0][0]']                  
                                128)                                                              
                                                                                                  
 batch_normalization_24 (BatchN  (None, 16, 16, 16,   512        ['conv3d_24[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_24 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_24[0][0]'] 
                                128)                                                              
                                                                                                  
 conv3d_25 (Conv3D)             (None, 16, 16, 16,   442496      ['leaky_re_lu_24[0][0]']         
                                128)                                                              
                                                                                                  
 batch_normalization_25 (BatchN  (None, 16, 16, 16,   512        ['conv3d_25[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_25 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_25[0][0]'] 
                                128)                                                              
                                                                                                  
 spatial_dropout3d_8 (SpatialDr  (None, 16, 16, 16,   0          ['leaky_re_lu_25[0][0]']         
 opout3D)                       128)                                                              
                                                                                                  
 conv3d_26 (Conv3D)             (None, 16, 16, 16,   442496      ['spatial_dropout3d_8[0][0]']    
                                128)                                                              
                                                                                                  
 batch_normalization_26 (BatchN  (None, 16, 16, 16,   512        ['conv3d_26[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_26 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_26[0][0]'] 
                                128)                                                              
                                                                                                  
 add_8 (Add)                    (None, 16, 16, 16,   0           ['leaky_re_lu_26[0][0]',         
                                128)                              'leaky_re_lu_24[0][0]']         
                                                                                                  
 conv3d_27 (Conv3D)             (None, 8, 8, 8, 256  884992      ['add_8[0][0]']                  
                                )                                                                 
                                                                                                  
 batch_normalization_27 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_27[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_27 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_27[0][0]'] 
                                )                                                                 
                                                                                                  
 conv3d_28 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['leaky_re_lu_27[0][0]']         
                                )                                                                 
                                                                                                  
 batch_normalization_28 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_28[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_28 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_28[0][0]'] 
                                )                                                                 
                                                                                                  
 spatial_dropout3d_9 (SpatialDr  (None, 8, 8, 8, 256  0          ['leaky_re_lu_28[0][0]']         
 opout3D)                       )                                                                 
                                                                                                  
 conv3d_29 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['spatial_dropout3d_9[0][0]']    
                                )                                                                 
                                                                                                  
 batch_normalization_29 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_29[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_29 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_29[0][0]'] 
                                )                                                                 
                                                                                                  
 add_9 (Add)                    (None, 8, 8, 8, 256  0           ['leaky_re_lu_29[0][0]',         
                                )                                 'leaky_re_lu_27[0][0]']         
                                                                                                  
 global_average_pooling3d_1 (Gl  (None, 256)         0           ['add_9[0][0]']                  
 obalAveragePooling3D)                                                                            
                                                                                                  
 dropout_1 (Dropout)            (None, 256)          0           ['global_average_pooling3d_1[0][0
                                                                 ]']                              
                                                                                                  
 dense_1 (Dense)                (None, 2)            514         ['dropout_1[0][0]']              
                                                                                                  
==================================================================================================
Total params: 5,897,410
Trainable params: 5,894,434
Non-trainable params: 2,976
__________________________________________________________________________________________________
Epoch 1/2
2024-09-15 12:04:54.461055: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
2024-09-15 12:05:00.925101: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
  1/138 [..............................] - ETA: 32:39 - loss: 2.0749 - accuracy: 0.5000 - auc: 0.2500  2/138 [..............................] - ETA: 17s - loss: 1.8409 - accuracy: 0.7500 - auc: 0.8125    3/138 [..............................] - ETA: 17s - loss: 2.5390 - accuracy: 0.5000 - auc: 0.4167  4/138 [..............................] - ETA: 16s - loss: 2.4384 - accuracy: 0.3750 - auc: 0.4219  5/138 [>.............................] - ETA: 16s - loss: 2.7292 - accuracy: 0.3000 - auc: 0.2700  6/138 [>.............................] - ETA: 16s - loss: 2.7903 - accuracy: 0.2500 - auc: 0.2153  7/138 [>.............................] - ETA: 16s - loss: 3.2790 - accuracy: 0.2143 - auc: 0.1582  8/138 [>.............................] - ETA: 16s - loss: 3.1721 - accuracy: 0.1875 - auc: 0.1445  9/138 [>.............................] - ETA: 16s - loss: 3.3671 - accuracy: 0.1667 - auc: 0.1142 10/138 [=>............................] - ETA: 16s - loss: 3.2305 - accuracy: 0.2000 - auc: 0.1375 11/138 [=>............................] - ETA: 15s - loss: 3.2661 - accuracy: 0.2273 - auc: 0.2004 12/138 [=>............................] - ETA: 15s - loss: 3.3235 - accuracy: 0.2083 - auc: 0.1788 13/138 [=>............................] - ETA: 15s - loss: 3.2325 - accuracy: 0.2308 - auc: 0.1805 14/138 [==>...........................] - ETA: 15s - loss: 3.1503 - accuracy: 0.2500 - auc: 0.2105 15/138 [==>...........................] - ETA: 15s - loss: 3.0337 - accuracy: 0.3000 - auc: 0.2733 16/138 [==>...........................] - ETA: 15s - loss: 3.0651 - accuracy: 0.3125 - auc: 0.2910 17/138 [==>...........................] - ETA: 15s - loss: 3.1370 - accuracy: 0.2941 - auc: 0.2673 18/138 [==>...........................] - ETA: 15s - loss: 3.0540 - accuracy: 0.3333 - auc: 0.3002 19/138 [===>..........................] - ETA: 14s - loss: 3.2977 - accuracy: 0.3158 - auc: 0.2708 20/138 [===>..........................] - ETA: 14s - loss: 3.2914 - accuracy: 0.3250 - auc: 0.2669 21/138 [===>..........................] - ETA: 14s - loss: 3.2498 - accuracy: 0.3333 - auc: 0.2812 22/138 [===>..........................] - ETA: 14s - loss: 3.1636 - accuracy: 0.3636 - auc: 0.3213 23/138 [====>.........................] - ETA: 14s - loss: 3.1192 - accuracy: 0.3696 - auc: 0.3199 24/138 [====>.........................] - ETA: 14s - loss: 3.1382 - accuracy: 0.3542 - auc: 0.3077 25/138 [====>.........................] - ETA: 14s - loss: 3.0921 - accuracy: 0.3600 - auc: 0.3120 26/138 [====>.........................] - ETA: 14s - loss: 3.0534 - accuracy: 0.3654 - auc: 0.3243 27/138 [====>.........................] - ETA: 13s - loss: 3.0381 - accuracy: 0.3704 - auc: 0.3405 28/138 [=====>........................] - ETA: 13s - loss: 3.0216 - accuracy: 0.3571 - auc: 0.3351 29/138 [=====>........................] - ETA: 13s - loss: 2.9950 - accuracy: 0.3621 - auc: 0.3439 30/138 [=====>........................] - ETA: 13s - loss: 2.9941 - accuracy: 0.3500 - auc: 0.3372 31/138 [=====>........................] - ETA: 13s - loss: 2.9513 - accuracy: 0.3710 - auc: 0.3499 32/138 [=====>........................] - ETA: 13s - loss: 2.9277 - accuracy: 0.3594 - auc: 0.3468 33/138 [======>.......................] - ETA: 13s - loss: 2.8823 - accuracy: 0.3788 - auc: 0.3711 34/138 [======>.......................] - ETA: 13s - loss: 2.8708 - accuracy: 0.3676 - auc: 0.3660 35/138 [======>.......................] - ETA: 12s - loss: 2.8643 - accuracy: 0.3714 - auc: 0.3709 36/138 [======>.......................] - ETA: 12s - loss: 2.8402 - accuracy: 0.3750 - auc: 0.3743 37/138 [=======>......................] - ETA: 12s - loss: 2.8116 - accuracy: 0.3919 - auc: 0.3827 38/138 [=======>......................] - ETA: 12s - loss: 2.7766 - accuracy: 0.4079 - auc: 0.3998 39/138 [=======>......................] - ETA: 12s - loss: 2.7686 - accuracy: 0.4103 - auc: 0.3987 40/138 [=======>......................] - ETA: 12s - loss: 2.7624 - accuracy: 0.4125 - auc: 0.3988 41/138 [=======>......................] - ETA: 12s - loss: 2.7378 - accuracy: 0.4146 - auc: 0.4068 42/138 [========>.....................] - ETA: 12s - loss: 2.7114 - accuracy: 0.4286 - auc: 0.4172 43/138 [========>.....................] - ETA: 11s - loss: 2.7047 - accuracy: 0.4302 - auc: 0.4193 44/138 [========>.....................] - ETA: 11s - loss: 2.7180 - accuracy: 0.4318 - auc: 0.4201 45/138 [========>.....................] - ETA: 11s - loss: 2.7164 - accuracy: 0.4222 - auc: 0.4135 46/138 [=========>....................] - ETA: 11s - loss: 2.6939 - accuracy: 0.4348 - auc: 0.4241 47/138 [=========>....................] - ETA: 11s - loss: 2.6880 - accuracy: 0.4362 - auc: 0.4303 48/138 [=========>....................] - ETA: 11s - loss: 2.6663 - accuracy: 0.4479 - auc: 0.4396 49/138 [=========>....................] - ETA: 11s - loss: 2.6404 - accuracy: 0.4592 - auc: 0.4565 50/138 [=========>....................] - ETA: 11s - loss: 2.6185 - accuracy: 0.4700 - auc: 0.4663 51/138 [==========>...................] - ETA: 10s - loss: 2.5997 - accuracy: 0.4804 - auc: 0.4735 52/138 [==========>...................] - ETA: 10s - loss: 2.5881 - accuracy: 0.4808 - auc: 0.4750 53/138 [==========>...................] - ETA: 10s - loss: 2.5663 - accuracy: 0.4906 - auc: 0.4867 54/138 [==========>...................] - ETA: 10s - loss: 2.5617 - accuracy: 0.4907 - auc: 0.4858 55/138 [==========>...................] - ETA: 10s - loss: 2.5486 - accuracy: 0.4909 - auc: 0.4910 56/138 [===========>..................] - ETA: 10s - loss: 2.5516 - accuracy: 0.4911 - auc: 0.4862 57/138 [===========>..................] - ETA: 10s - loss: 2.5313 - accuracy: 0.5000 - auc: 0.4990 58/138 [===========>..................] - ETA: 10s - loss: 2.5186 - accuracy: 0.5000 - auc: 0.5040 59/138 [===========>..................] - ETA: 9s - loss: 2.5594 - accuracy: 0.4915 - auc: 0.4929  60/138 [============>.................] - ETA: 9s - loss: 2.5541 - accuracy: 0.4917 - auc: 0.4952 61/138 [============>.................] - ETA: 9s - loss: 2.5403 - accuracy: 0.5000 - auc: 0.4996 62/138 [============>.................] - ETA: 9s - loss: 2.5305 - accuracy: 0.5000 - auc: 0.5008 63/138 [============>.................] - ETA: 9s - loss: 2.5210 - accuracy: 0.5000 - auc: 0.5025 64/138 [============>.................] - ETA: 9s - loss: 2.5067 - accuracy: 0.5078 - auc: 0.5105 65/138 [=============>................] - ETA: 9s - loss: 2.5092 - accuracy: 0.5077 - auc: 0.5070 66/138 [=============>................] - ETA: 9s - loss: 2.5055 - accuracy: 0.5076 - auc: 0.5061 67/138 [=============>................] - ETA: 8s - loss: 2.4932 - accuracy: 0.5149 - auc: 0.5117 68/138 [=============>................] - ETA: 8s - loss: 2.4786 - accuracy: 0.5221 - auc: 0.5199 69/138 [==============>...............] - ETA: 8s - loss: 2.4770 - accuracy: 0.5145 - auc: 0.5166 70/138 [==============>...............] - ETA: 8s - loss: 2.4707 - accuracy: 0.5143 - auc: 0.5176 71/138 [==============>...............] - ETA: 8s - loss: 2.4580 - accuracy: 0.5211 - auc: 0.5251 72/138 [==============>...............] - ETA: 8s - loss: 2.4445 - accuracy: 0.5278 - auc: 0.5326 73/138 [==============>...............] - ETA: 8s - loss: 2.4605 - accuracy: 0.5205 - auc: 0.5235 74/138 [===============>..............] - ETA: 8s - loss: 2.4640 - accuracy: 0.5203 - auc: 0.5215 75/138 [===============>..............] - ETA: 7s - loss: 2.4630 - accuracy: 0.5200 - auc: 0.5208 76/138 [===============>..............] - ETA: 7s - loss: 2.4564 - accuracy: 0.5197 - auc: 0.5218 77/138 [===============>..............] - ETA: 7s - loss: 2.4465 - accuracy: 0.5195 - auc: 0.5266 78/138 [===============>..............] - ETA: 7s - loss: 2.4451 - accuracy: 0.5128 - auc: 0.5236 79/138 [================>.............] - ETA: 7s - loss: 2.4347 - accuracy: 0.5190 - auc: 0.5292 80/138 [================>.............] - ETA: 7s - loss: 2.4248 - accuracy: 0.5250 - auc: 0.5336 81/138 [================>.............] - ETA: 7s - loss: 2.4400 - accuracy: 0.5185 - auc: 0.5247 82/138 [================>.............] - ETA: 7s - loss: 2.4314 - accuracy: 0.5244 - auc: 0.5278 83/138 [=================>............] - ETA: 6s - loss: 2.4278 - accuracy: 0.5241 - auc: 0.5284 84/138 [=================>............] - ETA: 6s - loss: 2.4183 - accuracy: 0.5298 - auc: 0.5331 85/138 [=================>............] - ETA: 6s - loss: 2.4283 - accuracy: 0.5294 - auc: 0.5303 86/138 [=================>............] - ETA: 6s - loss: 2.4198 - accuracy: 0.5349 - auc: 0.5337 87/138 [=================>............] - ETA: 6s - loss: 2.4197 - accuracy: 0.5345 - auc: 0.5337 88/138 [==================>...........] - ETA: 6s - loss: 2.4201 - accuracy: 0.5341 - auc: 0.5314 89/138 [==================>...........] - ETA: 6s - loss: 2.4086 - accuracy: 0.5393 - auc: 0.5389 90/138 [==================>...........] - ETA: 6s - loss: 2.4124 - accuracy: 0.5389 - auc: 0.5357 91/138 [==================>...........] - ETA: 5s - loss: 2.4102 - accuracy: 0.5385 - auc: 0.5365 92/138 [===================>..........] - ETA: 5s - loss: 2.4138 - accuracy: 0.5380 - auc: 0.5340 93/138 [===================>..........] - ETA: 5s - loss: 2.4208 - accuracy: 0.5323 - auc: 0.5282 94/138 [===================>..........] - ETA: 5s - loss: 2.4203 - accuracy: 0.5266 - auc: 0.5257 95/138 [===================>..........] - ETA: 5s - loss: 2.4124 - accuracy: 0.5316 - auc: 0.5290 96/138 [===================>..........] - ETA: 5s - loss: 2.4027 - accuracy: 0.5365 - auc: 0.5350 97/138 [====================>.........] - ETA: 5s - loss: 2.3927 - accuracy: 0.5412 - auc: 0.5412 98/138 [====================>.........] - ETA: 5s - loss: 2.3850 - accuracy: 0.5459 - auc: 0.5448 99/138 [====================>.........] - ETA: 4s - loss: 2.3939 - accuracy: 0.5455 - auc: 0.5402100/138 [====================>.........] - ETA: 4s - loss: 2.3981 - accuracy: 0.5400 - auc: 0.5364101/138 [====================>.........] - ETA: 4s - loss: 2.3913 - accuracy: 0.5396 - auc: 0.5399102/138 [=====================>........] - ETA: 4s - loss: 2.3868 - accuracy: 0.5392 - auc: 0.5420103/138 [=====================>........] - ETA: 4s - loss: 2.3772 - accuracy: 0.5437 - auc: 0.5484104/138 [=====================>........] - ETA: 4s - loss: 2.3804 - accuracy: 0.5433 - auc: 0.5477105/138 [=====================>........] - ETA: 4s - loss: 2.3740 - accuracy: 0.5476 - auc: 0.5501106/138 [======================>.......] - ETA: 4s - loss: 2.3748 - accuracy: 0.5425 - auc: 0.5475107/138 [======================>.......] - ETA: 3s - loss: 2.3678 - accuracy: 0.5467 - auc: 0.5515108/138 [======================>.......] - ETA: 3s - loss: 2.3661 - accuracy: 0.5463 - auc: 0.5523109/138 [======================>.......] - ETA: 3s - loss: 2.3592 - accuracy: 0.5505 - auc: 0.5557110/138 [======================>.......] - ETA: 3s - loss: 2.3511 - accuracy: 0.5545 - auc: 0.5605111/138 [=======================>......] - ETA: 3s - loss: 2.3431 - accuracy: 0.5586 - auc: 0.5657112/138 [=======================>......] - ETA: 3s - loss: 2.3424 - accuracy: 0.5536 - auc: 0.5636113/138 [=======================>......] - ETA: 3s - loss: 2.3386 - accuracy: 0.5531 - auc: 0.5643114/138 [=======================>......] - ETA: 3s - loss: 2.3304 - accuracy: 0.5570 - auc: 0.5697115/138 [========================>.....] - ETA: 2s - loss: 2.3309 - accuracy: 0.5565 - auc: 0.5695116/138 [========================>.....] - ETA: 2s - loss: 2.3333 - accuracy: 0.5560 - auc: 0.5683117/138 [========================>.....] - ETA: 2s - loss: 2.3269 - accuracy: 0.5598 - auc: 0.5714118/138 [========================>.....] - ETA: 2s - loss: 2.3209 - accuracy: 0.5636 - auc: 0.5743119/138 [========================>.....] - ETA: 2s - loss: 2.3188 - accuracy: 0.5630 - auc: 0.5736120/138 [=========================>....] - ETA: 2s - loss: 2.3167 - accuracy: 0.5625 - auc: 0.5737121/138 [=========================>....] - ETA: 2s - loss: 2.3156 - accuracy: 0.5620 - auc: 0.5735122/138 [=========================>....] - ETA: 2s - loss: 2.3246 - accuracy: 0.5574 - auc: 0.5676123/138 [=========================>....] - ETA: 1s - loss: 2.3188 - accuracy: 0.5610 - auc: 0.5701124/138 [=========================>....] - ETA: 1s - loss: 2.3124 - accuracy: 0.5645 - auc: 0.5741125/138 [==========================>...] - ETA: 1s - loss: 2.3055 - accuracy: 0.5680 - auc: 0.5783126/138 [==========================>...] - ETA: 1s - loss: 2.3010 - accuracy: 0.5675 - auc: 0.5802127/138 [==========================>...] - ETA: 1s - loss: 2.2966 - accuracy: 0.5669 - auc: 0.5819128/138 [==========================>...] - ETA: 1s - loss: 2.3033 - accuracy: 0.5664 - auc: 0.5802129/138 [===========================>..] - ETA: 1s - loss: 2.2969 - accuracy: 0.5698 - auc: 0.5839130/138 [===========================>..] - ETA: 1s - loss: 2.3043 - accuracy: 0.5654 - auc: 0.5786131/138 [===========================>..] - ETA: 0s - loss: 2.3090 - accuracy: 0.5649 - auc: 0.5762132/138 [===========================>..] - ETA: 0s - loss: 2.3039 - accuracy: 0.5682 - auc: 0.5784133/138 [===========================>..] - ETA: 0s - loss: 2.3003 - accuracy: 0.5677 - auc: 0.5804134/138 [============================>.] - ETA: 0s - loss: 2.3070 - accuracy: 0.5634 - auc: 0.5754135/138 [============================>.] - ETA: 0s - loss: 2.3036 - accuracy: 0.5630 - auc: 0.5763136/138 [============================>.] - ETA: 0s - loss: 2.2972 - accuracy: 0.5662 - auc: 0.5805137/138 [============================>.] - ETA: 0s - loss: 2.3020 - accuracy: 0.5657 - auc: 0.5777138/138 [==============================] - ETA: 0s - loss: 2.3019 - accuracy: 0.5616 - auc: 0.5761138/138 [==============================] - 36s 156ms/step - loss: 2.3019 - accuracy: 0.5616 - auc: 0.5761 - val_loss: 4.2896 - val_accuracy: 0.6377 - val_auc: 0.6377 - lr: 5.0000e-04
Epoch 2/2
  1/138 [..............................] - ETA: 17s - loss: 2.2292 - accuracy: 0.5000 - auc: 0.2500  2/138 [..............................] - ETA: 16s - loss: 1.9206 - accuracy: 0.7500 - auc: 0.5625  3/138 [..............................] - ETA: 17s - loss: 1.8267 - accuracy: 0.8333 - auc: 0.7500  4/138 [..............................] - ETA: 16s - loss: 1.9266 - accuracy: 0.7500 - auc: 0.6562  5/138 [>.............................] - ETA: 16s - loss: 1.9129 - accuracy: 0.8000 - auc: 0.7000  6/138 [>.............................] - ETA: 16s - loss: 1.8474 - accuracy: 0.8333 - auc: 0.7639  7/138 [>.............................] - ETA: 16s - loss: 2.0506 - accuracy: 0.7143 - auc: 0.5969  8/138 [>.............................] - ETA: 16s - loss: 2.0306 - accuracy: 0.6875 - auc: 0.6094  9/138 [>.............................] - ETA: 16s - loss: 2.2843 - accuracy: 0.6111 - auc: 0.4877 10/138 [=>............................] - ETA: 16s - loss: 2.2115 - accuracy: 0.6500 - auc: 0.5500 11/138 [=>............................] - ETA: 16s - loss: 2.2582 - accuracy: 0.6364 - auc: 0.5227 12/138 [=>............................] - ETA: 15s - loss: 2.3891 - accuracy: 0.5833 - auc: 0.4531 13/138 [=>............................] - ETA: 15s - loss: 2.3902 - accuracy: 0.5385 - auc: 0.4364 14/138 [==>...........................] - ETA: 15s - loss: 2.3422 - accuracy: 0.5357 - auc: 0.4745 15/138 [==>...........................] - ETA: 15s - loss: 2.3078 - accuracy: 0.5667 - auc: 0.4911 16/138 [==>...........................] - ETA: 15s - loss: 2.3210 - accuracy: 0.5312 - auc: 0.4678 17/138 [==>...........................] - ETA: 15s - loss: 2.3228 - accuracy: 0.5294 - auc: 0.4689 18/138 [==>...........................] - ETA: 15s - loss: 2.2721 - accuracy: 0.5556 - auc: 0.5131 19/138 [===>..........................] - ETA: 15s - loss: 2.3737 - accuracy: 0.5263 - auc: 0.4633 20/138 [===>..........................] - ETA: 14s - loss: 2.3834 - accuracy: 0.5250 - auc: 0.4694 21/138 [===>..........................] - ETA: 14s - loss: 2.3657 - accuracy: 0.5238 - auc: 0.4762 22/138 [===>..........................] - ETA: 14s - loss: 2.4042 - accuracy: 0.5227 - auc: 0.4618 23/138 [====>.........................] - ETA: 14s - loss: 2.4118 - accuracy: 0.5217 - auc: 0.4698 24/138 [====>.........................] - ETA: 14s - loss: 2.4094 - accuracy: 0.5000 - auc: 0.4614 25/138 [====>.........................] - ETA: 14s - loss: 2.3742 - accuracy: 0.5200 - auc: 0.4836 26/138 [====>.........................] - ETA: 14s - loss: 2.3587 - accuracy: 0.5192 - auc: 0.4867 27/138 [====>.........................] - ETA: 13s - loss: 2.3387 - accuracy: 0.5370 - auc: 0.4938 28/138 [=====>........................] - ETA: 13s - loss: 2.3314 - accuracy: 0.5357 - auc: 0.4908 29/138 [=====>........................] - ETA: 13s - loss: 2.3295 - accuracy: 0.5172 - auc: 0.4860 30/138 [=====>........................] - ETA: 13s - loss: 2.3058 - accuracy: 0.5333 - auc: 0.5000 31/138 [=====>........................] - ETA: 13s - loss: 2.2892 - accuracy: 0.5323 - auc: 0.5096 32/138 [=====>........................] - ETA: 13s - loss: 2.2647 - accuracy: 0.5469 - auc: 0.5256 33/138 [======>.......................] - ETA: 13s - loss: 2.2488 - accuracy: 0.5455 - auc: 0.5372 34/138 [======>.......................] - ETA: 13s - loss: 2.2524 - accuracy: 0.5441 - auc: 0.5331 35/138 [======>.......................] - ETA: 12s - loss: 2.2400 - accuracy: 0.5429 - auc: 0.5398 36/138 [======>.......................] - ETA: 12s - loss: 2.2405 - accuracy: 0.5417 - auc: 0.5368 37/138 [=======>......................] - ETA: 12s - loss: 2.2391 - accuracy: 0.5405 - auc: 0.5332 38/138 [=======>......................] - ETA: 12s - loss: 2.2387 - accuracy: 0.5395 - auc: 0.5327 39/138 [=======>......................] - ETA: 12s - loss: 2.2548 - accuracy: 0.5385 - auc: 0.5219 40/138 [=======>......................] - ETA: 12s - loss: 2.2442 - accuracy: 0.5375 - auc: 0.5259 41/138 [=======>......................] - ETA: 12s - loss: 2.2255 - accuracy: 0.5488 - auc: 0.5413 42/138 [========>.....................] - ETA: 12s - loss: 2.2490 - accuracy: 0.5357 - auc: 0.5251 43/138 [========>.....................] - ETA: 11s - loss: 2.2453 - accuracy: 0.5349 - auc: 0.5257 44/138 [========>.....................] - ETA: 11s - loss: 2.2449 - accuracy: 0.5341 - auc: 0.5210 45/138 [========>.....................] - ETA: 11s - loss: 2.2340 - accuracy: 0.5333 - auc: 0.5274 46/138 [=========>....................] - ETA: 11s - loss: 2.2583 - accuracy: 0.5217 - auc: 0.5154 47/138 [=========>....................] - ETA: 11s - loss: 2.2591 - accuracy: 0.5213 - auc: 0.5101 48/138 [=========>....................] - ETA: 11s - loss: 2.2428 - accuracy: 0.5312 - auc: 0.5234 49/138 [=========>....................] - ETA: 11s - loss: 2.2380 - accuracy: 0.5306 - auc: 0.5242 50/138 [=========>....................] - ETA: 11s - loss: 2.2303 - accuracy: 0.5400 - auc: 0.5266 51/138 [==========>...................] - ETA: 10s - loss: 2.2172 - accuracy: 0.5490 - auc: 0.5370 52/138 [==========>...................] - ETA: 10s - loss: 2.2293 - accuracy: 0.5481 - auc: 0.5294 53/138 [==========>...................] - ETA: 10s - loss: 2.2305 - accuracy: 0.5472 - auc: 0.5280 54/138 [==========>...................] - ETA: 10s - loss: 2.2171 - accuracy: 0.5556 - auc: 0.5376 55/138 [==========>...................] - ETA: 10s - loss: 2.2139 - accuracy: 0.5545 - auc: 0.5398 56/138 [===========>..................] - ETA: 10s - loss: 2.2226 - accuracy: 0.5536 - auc: 0.5350 57/138 [===========>..................] - ETA: 10s - loss: 2.2248 - accuracy: 0.5526 - auc: 0.5341 58/138 [===========>..................] - ETA: 10s - loss: 2.2272 - accuracy: 0.5517 - auc: 0.5303 59/138 [===========>..................] - ETA: 9s - loss: 2.2308 - accuracy: 0.5424 - auc: 0.5243  60/138 [============>.................] - ETA: 9s - loss: 2.2233 - accuracy: 0.5417 - auc: 0.5299 61/138 [============>.................] - ETA: 9s - loss: 2.2174 - accuracy: 0.5410 - auc: 0.5336 62/138 [============>.................] - ETA: 9s - loss: 2.2143 - accuracy: 0.5403 - auc: 0.5336 63/138 [============>.................] - ETA: 9s - loss: 2.2081 - accuracy: 0.5397 - auc: 0.5360 64/138 [============>.................] - ETA: 9s - loss: 2.2023 - accuracy: 0.5469 - auc: 0.5382 65/138 [=============>................] - ETA: 9s - loss: 2.1965 - accuracy: 0.5538 - auc: 0.5402 66/138 [=============>................] - ETA: 9s - loss: 2.1875 - accuracy: 0.5606 - auc: 0.5470 67/138 [=============>................] - ETA: 8s - loss: 2.1928 - accuracy: 0.5597 - auc: 0.5442 68/138 [=============>................] - ETA: 8s - loss: 2.1938 - accuracy: 0.5515 - auc: 0.5404 69/138 [==============>...............] - ETA: 8s - loss: 2.1960 - accuracy: 0.5507 - auc: 0.5393 70/138 [==============>...............] - ETA: 8s - loss: 2.1990 - accuracy: 0.5429 - auc: 0.5341 71/138 [==============>...............] - ETA: 8s - loss: 2.1997 - accuracy: 0.5423 - auc: 0.5317 72/138 [==============>...............] - ETA: 8s - loss: 2.1940 - accuracy: 0.5417 - auc: 0.5360 73/138 [==============>...............] - ETA: 8s - loss: 2.2152 - accuracy: 0.5342 - auc: 0.5243 74/138 [===============>..............] - ETA: 8s - loss: 2.2058 - accuracy: 0.5405 - auc: 0.5312 75/138 [===============>..............] - ETA: 7s - loss: 2.1966 - accuracy: 0.5467 - auc: 0.5383 76/138 [===============>..............] - ETA: 7s - loss: 2.1928 - accuracy: 0.5461 - auc: 0.5393 77/138 [===============>..............] - ETA: 7s - loss: 2.1941 - accuracy: 0.5390 - auc: 0.5356 78/138 [===============>..............] - ETA: 7s - loss: 2.1926 - accuracy: 0.5385 - auc: 0.5342 79/138 [================>.............] - ETA: 7s - loss: 2.1942 - accuracy: 0.5380 - auc: 0.5320 80/138 [================>.............] - ETA: 7s - loss: 2.1852 - accuracy: 0.5437 - auc: 0.5392 81/138 [================>.............] - ETA: 7s - loss: 2.1829 - accuracy: 0.5432 - auc: 0.5394 82/138 [================>.............] - ETA: 7s - loss: 2.1778 - accuracy: 0.5427 - auc: 0.5425 83/138 [=================>............] - ETA: 6s - loss: 2.1781 - accuracy: 0.5422 - auc: 0.5430 84/138 [=================>............] - ETA: 6s - loss: 2.1710 - accuracy: 0.5476 - auc: 0.5484 85/138 [=================>............] - ETA: 6s - loss: 2.1800 - accuracy: 0.5471 - auc: 0.5430 86/138 [=================>............] - ETA: 6s - loss: 2.1747 - accuracy: 0.5523 - auc: 0.5459 87/138 [=================>............] - ETA: 6s - loss: 2.1769 - accuracy: 0.5460 - auc: 0.5419 88/138 [==================>...........] - ETA: 6s - loss: 2.1712 - accuracy: 0.5511 - auc: 0.5455 89/138 [==================>...........] - ETA: 6s - loss: 2.1659 - accuracy: 0.5562 - auc: 0.5489 90/138 [==================>...........] - ETA: 6s - loss: 2.1692 - accuracy: 0.5556 - auc: 0.5448 91/138 [==================>...........] - ETA: 5s - loss: 2.1630 - accuracy: 0.5604 - auc: 0.5493 92/138 [===================>..........] - ETA: 5s - loss: 2.1649 - accuracy: 0.5543 - auc: 0.5457 93/138 [===================>..........] - ETA: 5s - loss: 2.1587 - accuracy: 0.5591 - auc: 0.5500 94/138 [===================>..........] - ETA: 5s - loss: 2.1582 - accuracy: 0.5585 - auc: 0.5499 95/138 [===================>..........] - ETA: 5s - loss: 2.1549 - accuracy: 0.5579 - auc: 0.5509 96/138 [===================>..........] - ETA: 5s - loss: 2.1600 - accuracy: 0.5521 - auc: 0.5460 97/138 [====================>.........] - ETA: 5s - loss: 2.1608 - accuracy: 0.5515 - auc: 0.5451 98/138 [====================>.........] - ETA: 5s - loss: 2.1581 - accuracy: 0.5510 - auc: 0.5459 99/138 [====================>.........] - ETA: 4s - loss: 2.1496 - accuracy: 0.5556 - auc: 0.5542100/138 [====================>.........] - ETA: 4s - loss: 2.1462 - accuracy: 0.5550 - auc: 0.5559101/138 [====================>.........] - ETA: 4s - loss: 2.1644 - accuracy: 0.5495 - auc: 0.5463102/138 [=====================>........] - ETA: 4s - loss: 2.1575 - accuracy: 0.5539 - auc: 0.5519103/138 [=====================>........] - ETA: 4s - loss: 2.1556 - accuracy: 0.5534 - auc: 0.5527104/138 [=====================>........] - ETA: 4s - loss: 2.1475 - accuracy: 0.5577 - auc: 0.5605105/138 [=====================>........] - ETA: 4s - loss: 2.1430 - accuracy: 0.5619 - auc: 0.5632106/138 [======================>.......] - ETA: 4s - loss: 2.1428 - accuracy: 0.5613 - auc: 0.5617107/138 [======================>.......] - ETA: 3s - loss: 2.1450 - accuracy: 0.5607 - auc: 0.5591108/138 [======================>.......] - ETA: 3s - loss: 2.1412 - accuracy: 0.5648 - auc: 0.5610109/138 [======================>.......] - ETA: 3s - loss: 2.1498 - accuracy: 0.5642 - auc: 0.5570110/138 [======================>.......] - ETA: 3s - loss: 2.1457 - accuracy: 0.5636 - auc: 0.5596111/138 [=======================>......] - ETA: 3s - loss: 2.1404 - accuracy: 0.5676 - auc: 0.5636112/138 [=======================>......] - ETA: 3s - loss: 2.1449 - accuracy: 0.5670 - auc: 0.5618113/138 [=======================>......] - ETA: 3s - loss: 2.1482 - accuracy: 0.5664 - auc: 0.5585114/138 [=======================>......] - ETA: 3s - loss: 2.1436 - accuracy: 0.5702 - auc: 0.5617115/138 [========================>.....] - ETA: 2s - loss: 2.1374 - accuracy: 0.5739 - auc: 0.5668116/138 [========================>.....] - ETA: 2s - loss: 2.1328 - accuracy: 0.5776 - auc: 0.5702117/138 [========================>.....] - ETA: 2s - loss: 2.1299 - accuracy: 0.5812 - auc: 0.5715118/138 [========================>.....] - ETA: 2s - loss: 2.1295 - accuracy: 0.5805 - auc: 0.5704119/138 [========================>.....] - ETA: 2s - loss: 2.1245 - accuracy: 0.5840 - auc: 0.5742120/138 [=========================>....] - ETA: 2s - loss: 2.1272 - accuracy: 0.5792 - auc: 0.5705121/138 [=========================>....] - ETA: 2s - loss: 2.1245 - accuracy: 0.5785 - auc: 0.5716122/138 [=========================>....] - ETA: 2s - loss: 2.1219 - accuracy: 0.5779 - auc: 0.5729123/138 [=========================>....] - ETA: 1s - loss: 2.1177 - accuracy: 0.5813 - auc: 0.5759124/138 [=========================>....] - ETA: 1s - loss: 2.1151 - accuracy: 0.5806 - auc: 0.5769125/138 [==========================>...] - ETA: 1s - loss: 2.1278 - accuracy: 0.5760 - auc: 0.5692126/138 [==========================>...] - ETA: 1s - loss: 2.1264 - accuracy: 0.5754 - auc: 0.5694127/138 [==========================>...] - ETA: 1s - loss: 2.1210 - accuracy: 0.5787 - auc: 0.5740128/138 [==========================>...] - ETA: 1s - loss: 2.1170 - accuracy: 0.5781 - auc: 0.5771129/138 [===========================>..] - ETA: 1s - loss: 2.1187 - accuracy: 0.5775 - auc: 0.5758130/138 [===========================>..] - ETA: 1s - loss: 2.1153 - accuracy: 0.5808 - auc: 0.5779131/138 [===========================>..] - ETA: 0s - loss: 2.1095 - accuracy: 0.5840 - auc: 0.5830132/138 [===========================>..] - ETA: 0s - loss: 2.1224 - accuracy: 0.5833 - auc: 0.5789133/138 [===========================>..] - ETA: 0s - loss: 2.1164 - accuracy: 0.5865 - auc: 0.5845134/138 [============================>.] - ETA: 0s - loss: 2.1109 - accuracy: 0.5896 - auc: 0.5890135/138 [============================>.] - ETA: 0s - loss: 2.1072 - accuracy: 0.5926 - auc: 0.5914136/138 [============================>.] - ETA: 0s - loss: 2.1069 - accuracy: 0.5919 - auc: 0.5916137/138 [============================>.] - ETA: 0s - loss: 2.1061 - accuracy: 0.5912 - auc: 0.5911138/138 [==============================] - ETA: 0s - loss: 2.1011 - accuracy: 0.5942 - auc: 0.5953138/138 [==============================] - 20s 144ms/step - loss: 2.1011 - accuracy: 0.5942 - auc: 0.5953 - val_loss: 1.8702 - val_accuracy: 0.6377 - val_auc: 0.6969 - lr: 5.0000e-04
Best val_auc during training for fold 1: 0.6969
Final AUC for fold 1: 0.6286
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               
                                28, 1)]                                                           
                                                                                                  
 conv3d_30 (Conv3D)             (None, 128, 128, 12  448         ['input_3[0][0]']                
                                8, 16)                                                            
                                                                                                  
 batch_normalization_30 (BatchN  (None, 128, 128, 12  64         ['conv3d_30[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_30 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_30[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 conv3d_31 (Conv3D)             (None, 128, 128, 12  6928        ['leaky_re_lu_30[0][0]']         
                                8, 16)                                                            
                                                                                                  
 batch_normalization_31 (BatchN  (None, 128, 128, 12  64         ['conv3d_31[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_31 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_31[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 spatial_dropout3d_10 (SpatialD  (None, 128, 128, 12  0          ['leaky_re_lu_31[0][0]']         
 ropout3D)                      8, 16)                                                            
                                                                                                  
 conv3d_32 (Conv3D)             (None, 128, 128, 12  6928        ['spatial_dropout3d_10[0][0]']   
                                8, 16)                                                            
                                                                                                  
 batch_normalization_32 (BatchN  (None, 128, 128, 12  64         ['conv3d_32[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_32 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_32[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 add_10 (Add)                   (None, 128, 128, 12  0           ['leaky_re_lu_32[0][0]',         
                                8, 16)                            'leaky_re_lu_30[0][0]']         
                                                                                                  
 conv3d_33 (Conv3D)             (None, 64, 64, 64,   13856       ['add_10[0][0]']                 
                                32)                                                               
                                                                                                  
 batch_normalization_33 (BatchN  (None, 64, 64, 64,   128        ['conv3d_33[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_33 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_33[0][0]'] 
                                32)                                                               
                                                                                                  
 conv3d_34 (Conv3D)             (None, 64, 64, 64,   27680       ['leaky_re_lu_33[0][0]']         
                                32)                                                               
                                                                                                  
 batch_normalization_34 (BatchN  (None, 64, 64, 64,   128        ['conv3d_34[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_34 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_34[0][0]'] 
                                32)                                                               
                                                                                                  
 spatial_dropout3d_11 (SpatialD  (None, 64, 64, 64,   0          ['leaky_re_lu_34[0][0]']         
 ropout3D)                      32)                                                               
                                                                                                  
 conv3d_35 (Conv3D)             (None, 64, 64, 64,   27680       ['spatial_dropout3d_11[0][0]']   
                                32)                                                               
                                                                                                  
 batch_normalization_35 (BatchN  (None, 64, 64, 64,   128        ['conv3d_35[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_35 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_35[0][0]'] 
                                32)                                                               
                                                                                                  
 add_11 (Add)                   (None, 64, 64, 64,   0           ['leaky_re_lu_35[0][0]',         
                                32)                               'leaky_re_lu_33[0][0]']         
                                                                                                  
 conv3d_36 (Conv3D)             (None, 32, 32, 32,   55360       ['add_11[0][0]']                 
                                64)                                                               
                                                                                                  
 batch_normalization_36 (BatchN  (None, 32, 32, 32,   256        ['conv3d_36[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_36 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_36[0][0]'] 
                                64)                                                               
                                                                                                  
 conv3d_37 (Conv3D)             (None, 32, 32, 32,   110656      ['leaky_re_lu_36[0][0]']         
                                64)                                                               
                                                                                                  
 batch_normalization_37 (BatchN  (None, 32, 32, 32,   256        ['conv3d_37[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_37 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_37[0][0]'] 
                                64)                                                               
                                                                                                  
 spatial_dropout3d_12 (SpatialD  (None, 32, 32, 32,   0          ['leaky_re_lu_37[0][0]']         
 ropout3D)                      64)                                                               
                                                                                                  
 conv3d_38 (Conv3D)             (None, 32, 32, 32,   110656      ['spatial_dropout3d_12[0][0]']   
                                64)                                                               
                                                                                                  
 batch_normalization_38 (BatchN  (None, 32, 32, 32,   256        ['conv3d_38[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_38 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_38[0][0]'] 
                                64)                                                               
                                                                                                  
 add_12 (Add)                   (None, 32, 32, 32,   0           ['leaky_re_lu_38[0][0]',         
                                64)                               'leaky_re_lu_36[0][0]']         
                                                                                                  
 conv3d_39 (Conv3D)             (None, 16, 16, 16,   221312      ['add_12[0][0]']                 
                                128)                                                              
                                                                                                  
 batch_normalization_39 (BatchN  (None, 16, 16, 16,   512        ['conv3d_39[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_39 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_39[0][0]'] 
                                128)                                                              
                                                                                                  
 conv3d_40 (Conv3D)             (None, 16, 16, 16,   442496      ['leaky_re_lu_39[0][0]']         
                                128)                                                              
                                                                                                  
 batch_normalization_40 (BatchN  (None, 16, 16, 16,   512        ['conv3d_40[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_40 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_40[0][0]'] 
                                128)                                                              
                                                                                                  
 spatial_dropout3d_13 (SpatialD  (None, 16, 16, 16,   0          ['leaky_re_lu_40[0][0]']         
 ropout3D)                      128)                                                              
                                                                                                  
 conv3d_41 (Conv3D)             (None, 16, 16, 16,   442496      ['spatial_dropout3d_13[0][0]']   
                                128)                                                              
                                                                                                  
 batch_normalization_41 (BatchN  (None, 16, 16, 16,   512        ['conv3d_41[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_41 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_41[0][0]'] 
                                128)                                                              
                                                                                                  
 add_13 (Add)                   (None, 16, 16, 16,   0           ['leaky_re_lu_41[0][0]',         
                                128)                              'leaky_re_lu_39[0][0]']         
                                                                                                  
 conv3d_42 (Conv3D)             (None, 8, 8, 8, 256  884992      ['add_13[0][0]']                 
                                )                                                                 
                                                                                                  
 batch_normalization_42 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_42[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_42 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_42[0][0]'] 
                                )                                                                 
                                                                                                  
 conv3d_43 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['leaky_re_lu_42[0][0]']         
                                )                                                                 
                                                                                                  
 batch_normalization_43 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_43[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_43 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_43[0][0]'] 
                                )                                                                 
                                                                                                  
 spatial_dropout3d_14 (SpatialD  (None, 8, 8, 8, 256  0          ['leaky_re_lu_43[0][0]']         
 ropout3D)                      )                                                                 
                                                                                                  
 conv3d_44 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['spatial_dropout3d_14[0][0]']   
                                )                                                                 
                                                                                                  
 batch_normalization_44 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_44[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_44 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_44[0][0]'] 
                                )                                                                 
                                                                                                  
 add_14 (Add)                   (None, 8, 8, 8, 256  0           ['leaky_re_lu_44[0][0]',         
                                )                                 'leaky_re_lu_42[0][0]']         
                                                                                                  
 global_average_pooling3d_2 (Gl  (None, 256)         0           ['add_14[0][0]']                 
 obalAveragePooling3D)                                                                            
                                                                                                  
 dropout_2 (Dropout)            (None, 256)          0           ['global_average_pooling3d_2[0][0
                                                                 ]']                              
                                                                                                  
 dense_2 (Dense)                (None, 2)            514         ['dropout_2[0][0]']              
                                                                                                  
==================================================================================================
Total params: 5,897,410
Trainable params: 5,894,434
Non-trainable params: 2,976
__________________________________________________________________________________________________
Epoch 1/2
  1/138 [..............................] - ETA: 4:21 - loss: 1.4332 - accuracy: 1.0000 - auc: 1.0000  2/138 [..............................] - ETA: 19s - loss: 1.6457 - accuracy: 0.7500 - auc: 0.9375   3/138 [..............................] - ETA: 18s - loss: 1.5642 - accuracy: 0.8333 - auc: 0.9722  4/138 [..............................] - ETA: 17s - loss: 1.5502 - accuracy: 0.8750 - auc: 0.9844  5/138 [>.............................] - ETA: 17s - loss: 1.6327 - accuracy: 0.8000 - auc: 0.9600  6/138 [>.............................] - ETA: 17s - loss: 1.6021 - accuracy: 0.8333 - auc: 0.9722  7/138 [>.............................] - ETA: 16s - loss: 1.6634 - accuracy: 0.7857 - auc: 0.9337  8/138 [>.............................] - ETA: 16s - loss: 1.6516 - accuracy: 0.8125 - auc: 0.9258  9/138 [>.............................] - ETA: 16s - loss: 1.8549 - accuracy: 0.7222 - auc: 0.8086 10/138 [=>............................] - ETA: 16s - loss: 2.1710 - accuracy: 0.7000 - auc: 0.7425 11/138 [=>............................] - ETA: 16s - loss: 2.1915 - accuracy: 0.6818 - auc: 0.7190 12/138 [=>............................] - ETA: 16s - loss: 2.3307 - accuracy: 0.6250 - auc: 0.6389 13/138 [=>............................] - ETA: 15s - loss: 2.3000 - accuracy: 0.6154 - auc: 0.6524 14/138 [==>...........................] - ETA: 15s - loss: 2.2901 - accuracy: 0.6071 - auc: 0.6454 15/138 [==>...........................] - ETA: 15s - loss: 2.2814 - accuracy: 0.6000 - auc: 0.6489 16/138 [==>...........................] - ETA: 15s - loss: 2.2207 - accuracy: 0.6250 - auc: 0.6855 17/138 [==>...........................] - ETA: 15s - loss: 2.2043 - accuracy: 0.6176 - auc: 0.6920 18/138 [==>...........................] - ETA: 15s - loss: 2.4038 - accuracy: 0.5833 - auc: 0.6358 19/138 [===>..........................] - ETA: 15s - loss: 2.5195 - accuracy: 0.5789 - auc: 0.6198 20/138 [===>..........................] - ETA: 14s - loss: 2.6689 - accuracy: 0.5750 - auc: 0.6075 21/138 [===>..........................] - ETA: 14s - loss: 2.6457 - accuracy: 0.5714 - auc: 0.6015 22/138 [===>..........................] - ETA: 14s - loss: 2.5852 - accuracy: 0.5909 - auc: 0.6296 23/138 [====>.........................] - ETA: 14s - loss: 2.5548 - accuracy: 0.5870 - auc: 0.6380 24/138 [====>.........................] - ETA: 14s - loss: 2.6239 - accuracy: 0.5833 - auc: 0.6228 25/138 [====>.........................] - ETA: 14s - loss: 2.6072 - accuracy: 0.5600 - auc: 0.6180 26/138 [====>.........................] - ETA: 14s - loss: 2.5768 - accuracy: 0.5577 - auc: 0.6250 27/138 [====>.........................] - ETA: 14s - loss: 2.5544 - accuracy: 0.5556 - auc: 0.6272 28/138 [=====>........................] - ETA: 13s - loss: 2.5118 - accuracy: 0.5714 - auc: 0.6467 29/138 [=====>........................] - ETA: 13s - loss: 2.4790 - accuracy: 0.5862 - auc: 0.6558 30/138 [=====>........................] - ETA: 13s - loss: 2.4687 - accuracy: 0.5833 - auc: 0.6569 31/138 [=====>........................] - ETA: 13s - loss: 2.4353 - accuracy: 0.5968 - auc: 0.6712 32/138 [=====>........................] - ETA: 13s - loss: 2.4359 - accuracy: 0.5938 - auc: 0.6665 33/138 [======>.......................] - ETA: 13s - loss: 2.4056 - accuracy: 0.6061 - auc: 0.6781 34/138 [======>.......................] - ETA: 13s - loss: 2.4145 - accuracy: 0.6029 - auc: 0.6747 35/138 [======>.......................] - ETA: 13s - loss: 2.4491 - accuracy: 0.5857 - auc: 0.6573 36/138 [======>.......................] - ETA: 12s - loss: 2.4944 - accuracy: 0.5833 - auc: 0.6437 37/138 [=======>......................] - ETA: 12s - loss: 2.4866 - accuracy: 0.5811 - auc: 0.6437 38/138 [=======>......................] - ETA: 12s - loss: 2.4725 - accuracy: 0.5789 - auc: 0.6465 39/138 [=======>......................] - ETA: 12s - loss: 2.4464 - accuracy: 0.5897 - auc: 0.6566 40/138 [=======>......................] - ETA: 12s - loss: 2.4311 - accuracy: 0.5875 - auc: 0.6581 41/138 [=======>......................] - ETA: 12s - loss: 2.4195 - accuracy: 0.5854 - auc: 0.6605 42/138 [========>.....................] - ETA: 12s - loss: 2.4108 - accuracy: 0.5833 - auc: 0.6593 43/138 [========>.....................] - ETA: 11s - loss: 2.4029 - accuracy: 0.5814 - auc: 0.6606 44/138 [========>.....................] - ETA: 11s - loss: 2.3983 - accuracy: 0.5795 - auc: 0.6586 45/138 [========>.....................] - ETA: 11s - loss: 2.4139 - accuracy: 0.5778 - auc: 0.6510 46/138 [=========>....................] - ETA: 11s - loss: 2.4807 - accuracy: 0.5652 - auc: 0.6283 47/138 [=========>....................] - ETA: 11s - loss: 2.4863 - accuracy: 0.5638 - auc: 0.6203 48/138 [=========>....................] - ETA: 11s - loss: 2.4894 - accuracy: 0.5625 - auc: 0.6192 49/138 [=========>....................] - ETA: 11s - loss: 2.4691 - accuracy: 0.5714 - auc: 0.6267 50/138 [=========>....................] - ETA: 11s - loss: 2.4691 - accuracy: 0.5700 - auc: 0.6206 51/138 [==========>...................] - ETA: 10s - loss: 2.4586 - accuracy: 0.5686 - auc: 0.6233 52/138 [==========>...................] - ETA: 10s - loss: 2.4406 - accuracy: 0.5769 - auc: 0.6296 53/138 [==========>...................] - ETA: 10s - loss: 2.4319 - accuracy: 0.5755 - auc: 0.6325 54/138 [==========>...................] - ETA: 10s - loss: 2.4500 - accuracy: 0.5648 - auc: 0.6229 55/138 [==========>...................] - ETA: 10s - loss: 2.4380 - accuracy: 0.5636 - auc: 0.6270 56/138 [===========>..................] - ETA: 10s - loss: 2.4318 - accuracy: 0.5625 - auc: 0.6253 57/138 [===========>..................] - ETA: 10s - loss: 2.4257 - accuracy: 0.5614 - auc: 0.6263 58/138 [===========>..................] - ETA: 10s - loss: 2.4222 - accuracy: 0.5603 - auc: 0.6228 59/138 [===========>..................] - ETA: 9s - loss: 2.4299 - accuracy: 0.5508 - auc: 0.6151  60/138 [============>.................] - ETA: 9s - loss: 2.4193 - accuracy: 0.5583 - auc: 0.6149 61/138 [============>.................] - ETA: 9s - loss: 2.4081 - accuracy: 0.5574 - auc: 0.6188 62/138 [============>.................] - ETA: 9s - loss: 2.4090 - accuracy: 0.5565 - auc: 0.6172 63/138 [============>.................] - ETA: 9s - loss: 2.4037 - accuracy: 0.5556 - auc: 0.6184 64/138 [============>.................] - ETA: 9s - loss: 2.4195 - accuracy: 0.5547 - auc: 0.6135 65/138 [=============>................] - ETA: 9s - loss: 2.4049 - accuracy: 0.5615 - auc: 0.6199 66/138 [=============>................] - ETA: 9s - loss: 2.4155 - accuracy: 0.5530 - auc: 0.6127 67/138 [=============>................] - ETA: 8s - loss: 2.4213 - accuracy: 0.5522 - auc: 0.6097 68/138 [=============>................] - ETA: 8s - loss: 2.4123 - accuracy: 0.5515 - auc: 0.6128 69/138 [==============>...............] - ETA: 8s - loss: 2.4162 - accuracy: 0.5507 - auc: 0.6076 70/138 [==============>...............] - ETA: 8s - loss: 2.4030 - accuracy: 0.5571 - auc: 0.6132 71/138 [==============>...............] - ETA: 8s - loss: 2.3984 - accuracy: 0.5563 - auc: 0.6111 72/138 [==============>...............] - ETA: 8s - loss: 2.4185 - accuracy: 0.5486 - auc: 0.6017 73/138 [==============>...............] - ETA: 8s - loss: 2.4089 - accuracy: 0.5548 - auc: 0.6041 74/138 [===============>..............] - ETA: 8s - loss: 2.4030 - accuracy: 0.5541 - auc: 0.6035 75/138 [===============>..............] - ETA: 7s - loss: 2.4003 - accuracy: 0.5533 - auc: 0.6037 76/138 [===============>..............] - ETA: 7s - loss: 2.3928 - accuracy: 0.5526 - auc: 0.6043 77/138 [===============>..............] - ETA: 7s - loss: 2.3835 - accuracy: 0.5584 - auc: 0.6074 78/138 [===============>..............] - ETA: 7s - loss: 2.3814 - accuracy: 0.5577 - auc: 0.6058 79/138 [================>.............] - ETA: 7s - loss: 2.3701 - accuracy: 0.5633 - auc: 0.6108 80/138 [================>.............] - ETA: 7s - loss: 2.3688 - accuracy: 0.5562 - auc: 0.6084 81/138 [================>.............] - ETA: 7s - loss: 2.3634 - accuracy: 0.5556 - auc: 0.6096 82/138 [================>.............] - ETA: 7s - loss: 2.3608 - accuracy: 0.5488 - auc: 0.6074 83/138 [=================>............] - ETA: 6s - loss: 2.3497 - accuracy: 0.5542 - auc: 0.6136 84/138 [=================>............] - ETA: 6s - loss: 2.3440 - accuracy: 0.5536 - auc: 0.6139 85/138 [=================>............] - ETA: 6s - loss: 2.3444 - accuracy: 0.5529 - auc: 0.6105 86/138 [=================>............] - ETA: 6s - loss: 2.3347 - accuracy: 0.5581 - auc: 0.6153 87/138 [=================>............] - ETA: 6s - loss: 2.3243 - accuracy: 0.5632 - auc: 0.6212 88/138 [==================>...........] - ETA: 6s - loss: 2.3389 - accuracy: 0.5568 - auc: 0.6126 89/138 [==================>...........] - ETA: 6s - loss: 2.3434 - accuracy: 0.5562 - auc: 0.6109 90/138 [==================>...........] - ETA: 6s - loss: 2.3405 - accuracy: 0.5556 - auc: 0.6120 91/138 [==================>...........] - ETA: 5s - loss: 2.3357 - accuracy: 0.5604 - auc: 0.6114 92/138 [===================>..........] - ETA: 5s - loss: 2.3349 - accuracy: 0.5598 - auc: 0.6109 93/138 [===================>..........] - ETA: 5s - loss: 2.3316 - accuracy: 0.5591 - auc: 0.6095 94/138 [===================>..........] - ETA: 5s - loss: 2.3346 - accuracy: 0.5532 - auc: 0.6053 95/138 [===================>..........] - ETA: 5s - loss: 2.3268 - accuracy: 0.5579 - auc: 0.6089 96/138 [===================>..........] - ETA: 5s - loss: 2.3349 - accuracy: 0.5573 - auc: 0.6047 97/138 [====================>.........] - ETA: 5s - loss: 2.3290 - accuracy: 0.5567 - auc: 0.6065 98/138 [====================>.........] - ETA: 5s - loss: 2.3393 - accuracy: 0.5510 - auc: 0.6008 99/138 [====================>.........] - ETA: 4s - loss: 2.3406 - accuracy: 0.5505 - auc: 0.5977100/138 [====================>.........] - ETA: 4s - loss: 2.3485 - accuracy: 0.5500 - auc: 0.5951101/138 [====================>.........] - ETA: 4s - loss: 2.3436 - accuracy: 0.5495 - auc: 0.5955102/138 [=====================>........] - ETA: 4s - loss: 2.3432 - accuracy: 0.5490 - auc: 0.5949103/138 [=====================>........] - ETA: 4s - loss: 2.3409 - accuracy: 0.5437 - auc: 0.5932104/138 [=====================>........] - ETA: 4s - loss: 2.3341 - accuracy: 0.5481 - auc: 0.5959105/138 [=====================>........] - ETA: 4s - loss: 2.3297 - accuracy: 0.5476 - auc: 0.5968106/138 [======================>.......] - ETA: 4s - loss: 2.3222 - accuracy: 0.5519 - auc: 0.6004107/138 [======================>.......] - ETA: 3s - loss: 2.3156 - accuracy: 0.5561 - auc: 0.6032108/138 [======================>.......] - ETA: 3s - loss: 2.3264 - accuracy: 0.5509 - auc: 0.5972109/138 [======================>.......] - ETA: 3s - loss: 2.3267 - accuracy: 0.5459 - auc: 0.5946110/138 [======================>.......] - ETA: 3s - loss: 2.3329 - accuracy: 0.5455 - auc: 0.5929111/138 [=======================>......] - ETA: 3s - loss: 2.3304 - accuracy: 0.5450 - auc: 0.5920112/138 [=======================>......] - ETA: 3s - loss: 2.3217 - accuracy: 0.5491 - auc: 0.5974113/138 [=======================>......] - ETA: 3s - loss: 2.3146 - accuracy: 0.5531 - auc: 0.6008114/138 [=======================>......] - ETA: 3s - loss: 2.3173 - accuracy: 0.5526 - auc: 0.5978115/138 [========================>.....] - ETA: 2s - loss: 2.3169 - accuracy: 0.5522 - auc: 0.5973116/138 [========================>.....] - ETA: 2s - loss: 2.3132 - accuracy: 0.5517 - auc: 0.5978117/138 [========================>.....] - ETA: 2s - loss: 2.3080 - accuracy: 0.5556 - auc: 0.5996118/138 [========================>.....] - ETA: 2s - loss: 2.3020 - accuracy: 0.5593 - auc: 0.6022119/138 [========================>.....] - ETA: 2s - loss: 2.2961 - accuracy: 0.5630 - auc: 0.6047120/138 [=========================>....] - ETA: 2s - loss: 2.3064 - accuracy: 0.5583 - auc: 0.5996121/138 [=========================>....] - ETA: 2s - loss: 2.3161 - accuracy: 0.5537 - auc: 0.5942122/138 [=========================>....] - ETA: 2s - loss: 2.3169 - accuracy: 0.5533 - auc: 0.5926123/138 [=========================>....] - ETA: 1s - loss: 2.3109 - accuracy: 0.5569 - auc: 0.5954124/138 [=========================>....] - ETA: 1s - loss: 2.3062 - accuracy: 0.5565 - auc: 0.5969125/138 [==========================>...] - ETA: 1s - loss: 2.3083 - accuracy: 0.5560 - auc: 0.5945126/138 [==========================>...] - ETA: 1s - loss: 2.3091 - accuracy: 0.5556 - auc: 0.5931127/138 [==========================>...] - ETA: 1s - loss: 2.3161 - accuracy: 0.5512 - auc: 0.5880128/138 [==========================>...] - ETA: 1s - loss: 2.3132 - accuracy: 0.5508 - auc: 0.5876129/138 [===========================>..] - ETA: 1s - loss: 2.3074 - accuracy: 0.5543 - auc: 0.5905130/138 [===========================>..] - ETA: 1s - loss: 2.3062 - accuracy: 0.5538 - auc: 0.5894131/138 [===========================>..] - ETA: 0s - loss: 2.3103 - accuracy: 0.5496 - auc: 0.5854132/138 [===========================>..] - ETA: 0s - loss: 2.3054 - accuracy: 0.5492 - auc: 0.5877133/138 [===========================>..] - ETA: 0s - loss: 2.3026 - accuracy: 0.5489 - auc: 0.5887134/138 [============================>.] - ETA: 0s - loss: 2.2972 - accuracy: 0.5522 - auc: 0.5912135/138 [============================>.] - ETA: 0s - loss: 2.2904 - accuracy: 0.5556 - auc: 0.5956136/138 [============================>.] - ETA: 0s - loss: 2.2916 - accuracy: 0.5551 - auc: 0.5938137/138 [============================>.] - ETA: 0s - loss: 2.2976 - accuracy: 0.5511 - auc: 0.5893138/138 [==============================] - ETA: 0s - loss: 2.2965 - accuracy: 0.5471 - auc: 0.5879138/138 [==============================] - 23s 156ms/step - loss: 2.2965 - accuracy: 0.5471 - auc: 0.5879 - val_loss: 3.4404 - val_accuracy: 0.3623 - val_auc: 0.2641 - lr: 5.0000e-04
Epoch 2/2
  1/138 [..............................] - ETA: 17s - loss: 2.3799 - accuracy: 0.5000 - auc: 0.2500  2/138 [..............................] - ETA: 17s - loss: 1.9742 - accuracy: 0.7500 - auc: 0.5625  3/138 [..............................] - ETA: 16s - loss: 1.9107 - accuracy: 0.6667 - auc: 0.6667  4/138 [..............................] - ETA: 16s - loss: 1.9308 - accuracy: 0.6250 - auc: 0.6875  5/138 [>.............................] - ETA: 16s - loss: 1.8352 - accuracy: 0.7000 - auc: 0.7800  6/138 [>.............................] - ETA: 16s - loss: 1.9568 - accuracy: 0.6667 - auc: 0.6875  7/138 [>.............................] - ETA: 16s - loss: 2.0773 - accuracy: 0.6429 - auc: 0.6224  8/138 [>.............................] - ETA: 16s - loss: 2.0055 - accuracy: 0.6875 - auc: 0.6641  9/138 [>.............................] - ETA: 16s - loss: 1.9895 - accuracy: 0.6667 - auc: 0.6821 10/138 [=>............................] - ETA: 16s - loss: 1.9657 - accuracy: 0.6500 - auc: 0.6950 11/138 [=>............................] - ETA: 15s - loss: 2.0061 - accuracy: 0.6364 - auc: 0.6508 12/138 [=>............................] - ETA: 15s - loss: 2.0369 - accuracy: 0.6250 - auc: 0.6267 13/138 [=>............................] - ETA: 15s - loss: 2.0361 - accuracy: 0.6154 - auc: 0.6228 14/138 [==>...........................] - ETA: 15s - loss: 2.0055 - accuracy: 0.6429 - auc: 0.6441 15/138 [==>...........................] - ETA: 15s - loss: 2.0312 - accuracy: 0.6333 - auc: 0.6200 16/138 [==>...........................] - ETA: 15s - loss: 2.0105 - accuracy: 0.6562 - auc: 0.6367 17/138 [==>...........................] - ETA: 15s - loss: 2.0338 - accuracy: 0.6176 - auc: 0.6263 18/138 [==>...........................] - ETA: 15s - loss: 2.0105 - accuracy: 0.6389 - auc: 0.6474 19/138 [===>..........................] - ETA: 14s - loss: 2.0181 - accuracy: 0.6316 - auc: 0.6371 20/138 [===>..........................] - ETA: 14s - loss: 2.0333 - accuracy: 0.6250 - auc: 0.6200 21/138 [===>..........................] - ETA: 14s - loss: 2.0385 - accuracy: 0.6190 - auc: 0.6105 22/138 [===>..........................] - ETA: 14s - loss: 2.0214 - accuracy: 0.6136 - auc: 0.6229 23/138 [====>.........................] - ETA: 14s - loss: 2.0447 - accuracy: 0.5870 - auc: 0.5955 24/138 [====>.........................] - ETA: 14s - loss: 2.0198 - accuracy: 0.6042 - auc: 0.6185 25/138 [====>.........................] - ETA: 14s - loss: 2.0163 - accuracy: 0.6000 - auc: 0.6240 26/138 [====>.........................] - ETA: 14s - loss: 2.0480 - accuracy: 0.5962 - auc: 0.6054 27/138 [====>.........................] - ETA: 13s - loss: 2.0502 - accuracy: 0.5926 - auc: 0.6022 28/138 [=====>........................] - ETA: 13s - loss: 2.0313 - accuracy: 0.6071 - auc: 0.6196 29/138 [=====>........................] - ETA: 13s - loss: 2.0076 - accuracy: 0.6207 - auc: 0.6424 30/138 [=====>........................] - ETA: 13s - loss: 2.0094 - accuracy: 0.6167 - auc: 0.6394 31/138 [=====>........................] - ETA: 13s - loss: 2.0312 - accuracy: 0.6129 - auc: 0.6267 32/138 [=====>........................] - ETA: 13s - loss: 2.0456 - accuracy: 0.6094 - auc: 0.6196 33/138 [======>.......................] - ETA: 13s - loss: 2.0424 - accuracy: 0.6061 - auc: 0.6228 34/138 [======>.......................] - ETA: 13s - loss: 2.0490 - accuracy: 0.6029 - auc: 0.6161 35/138 [======>.......................] - ETA: 12s - loss: 2.0364 - accuracy: 0.6143 - auc: 0.6231 36/138 [======>.......................] - ETA: 12s - loss: 2.0408 - accuracy: 0.6111 - auc: 0.6184 37/138 [=======>......................] - ETA: 12s - loss: 2.0655 - accuracy: 0.5946 - auc: 0.5979 38/138 [=======>......................] - ETA: 12s - loss: 2.0838 - accuracy: 0.5921 - auc: 0.5902 39/138 [=======>......................] - ETA: 12s - loss: 2.0757 - accuracy: 0.6026 - auc: 0.5939 40/138 [=======>......................] - ETA: 12s - loss: 2.1125 - accuracy: 0.5875 - auc: 0.5691 41/138 [=======>......................] - ETA: 12s - loss: 2.1150 - accuracy: 0.5732 - auc: 0.5654 42/138 [========>.....................] - ETA: 12s - loss: 2.1047 - accuracy: 0.5714 - auc: 0.5730 43/138 [========>.....................] - ETA: 11s - loss: 2.1102 - accuracy: 0.5581 - auc: 0.5667 44/138 [========>.....................] - ETA: 11s - loss: 2.1206 - accuracy: 0.5568 - auc: 0.5610 45/138 [========>.....................] - ETA: 11s - loss: 2.1240 - accuracy: 0.5556 - auc: 0.5605 46/138 [=========>....................] - ETA: 11s - loss: 2.1260 - accuracy: 0.5435 - auc: 0.5560 47/138 [=========>....................] - ETA: 11s - loss: 2.1103 - accuracy: 0.5532 - auc: 0.5708 48/138 [=========>....................] - ETA: 11s - loss: 2.1053 - accuracy: 0.5521 - auc: 0.5757 49/138 [=========>....................] - ETA: 11s - loss: 2.0952 - accuracy: 0.5612 - auc: 0.5822 50/138 [=========>....................] - ETA: 11s - loss: 2.0852 - accuracy: 0.5700 - auc: 0.5886 51/138 [==========>...................] - ETA: 10s - loss: 2.0792 - accuracy: 0.5686 - auc: 0.5926 52/138 [==========>...................] - ETA: 10s - loss: 2.0810 - accuracy: 0.5673 - auc: 0.5921 53/138 [==========>...................] - ETA: 10s - loss: 2.0817 - accuracy: 0.5660 - auc: 0.5891 54/138 [==========>...................] - ETA: 10s - loss: 2.0704 - accuracy: 0.5741 - auc: 0.5980 55/138 [==========>...................] - ETA: 10s - loss: 2.0598 - accuracy: 0.5818 - auc: 0.6065 56/138 [===========>..................] - ETA: 10s - loss: 2.0667 - accuracy: 0.5804 - auc: 0.5997 57/138 [===========>..................] - ETA: 10s - loss: 2.0710 - accuracy: 0.5789 - auc: 0.5942 58/138 [===========>..................] - ETA: 10s - loss: 2.0643 - accuracy: 0.5862 - auc: 0.5974 59/138 [===========>..................] - ETA: 9s - loss: 2.0606 - accuracy: 0.5932 - auc: 0.5982  60/138 [============>.................] - ETA: 9s - loss: 2.0538 - accuracy: 0.5917 - auc: 0.6030 61/138 [============>.................] - ETA: 9s - loss: 2.0598 - accuracy: 0.5820 - auc: 0.5963 62/138 [============>.................] - ETA: 9s - loss: 2.0564 - accuracy: 0.5806 - auc: 0.5975 63/138 [============>.................] - ETA: 9s - loss: 2.0589 - accuracy: 0.5794 - auc: 0.5967 64/138 [============>.................] - ETA: 9s - loss: 2.0528 - accuracy: 0.5781 - auc: 0.6016 65/138 [=============>................] - ETA: 9s - loss: 2.0580 - accuracy: 0.5769 - auc: 0.5988 66/138 [=============>................] - ETA: 9s - loss: 2.0467 - accuracy: 0.5833 - auc: 0.6099 67/138 [=============>................] - ETA: 8s - loss: 2.0527 - accuracy: 0.5821 - auc: 0.6036 68/138 [=============>................] - ETA: 8s - loss: 2.0641 - accuracy: 0.5735 - auc: 0.5936 69/138 [==============>...............] - ETA: 8s - loss: 2.0804 - accuracy: 0.5652 - auc: 0.5835 70/138 [==============>...............] - ETA: 8s - loss: 2.0745 - accuracy: 0.5643 - auc: 0.5871 71/138 [==============>...............] - ETA: 8s - loss: 2.0650 - accuracy: 0.5704 - auc: 0.5958 72/138 [==============>...............] - ETA: 8s - loss: 2.0679 - accuracy: 0.5694 - auc: 0.5918 73/138 [==============>...............] - ETA: 8s - loss: 2.0750 - accuracy: 0.5616 - auc: 0.5849 74/138 [===============>..............] - ETA: 8s - loss: 2.0651 - accuracy: 0.5676 - auc: 0.5942 75/138 [===============>..............] - ETA: 7s - loss: 2.0634 - accuracy: 0.5667 - auc: 0.5936 76/138 [===============>..............] - ETA: 7s - loss: 2.0658 - accuracy: 0.5658 - auc: 0.5929 77/138 [===============>..............] - ETA: 7s - loss: 2.0602 - accuracy: 0.5714 - auc: 0.5964 78/138 [===============>..............] - ETA: 7s - loss: 2.0562 - accuracy: 0.5705 - auc: 0.5989 79/138 [================>.............] - ETA: 7s - loss: 2.0504 - accuracy: 0.5759 - auc: 0.6027 80/138 [================>.............] - ETA: 7s - loss: 2.0441 - accuracy: 0.5813 - auc: 0.6077 81/138 [================>.............] - ETA: 7s - loss: 2.0435 - accuracy: 0.5802 - auc: 0.6063 82/138 [================>.............] - ETA: 7s - loss: 2.0426 - accuracy: 0.5793 - auc: 0.6050 83/138 [=================>............] - ETA: 6s - loss: 2.0343 - accuracy: 0.5843 - auc: 0.6125 84/138 [=================>............] - ETA: 6s - loss: 2.0313 - accuracy: 0.5893 - auc: 0.6134 85/138 [=================>............] - ETA: 6s - loss: 2.0361 - accuracy: 0.5824 - auc: 0.6080 86/138 [=================>............] - ETA: 6s - loss: 2.0468 - accuracy: 0.5756 - auc: 0.5997 87/138 [=================>............] - ETA: 6s - loss: 2.0541 - accuracy: 0.5690 - auc: 0.5938 88/138 [==================>...........] - ETA: 6s - loss: 2.0490 - accuracy: 0.5682 - auc: 0.5975 89/138 [==================>...........] - ETA: 6s - loss: 2.0462 - accuracy: 0.5730 - auc: 0.5981 90/138 [==================>...........] - ETA: 6s - loss: 2.0442 - accuracy: 0.5722 - auc: 0.5998 91/138 [==================>...........] - ETA: 5s - loss: 2.0445 - accuracy: 0.5714 - auc: 0.5980 92/138 [===================>..........] - ETA: 5s - loss: 2.0444 - accuracy: 0.5707 - auc: 0.5968 93/138 [===================>..........] - ETA: 5s - loss: 2.0422 - accuracy: 0.5699 - auc: 0.5969 94/138 [===================>..........] - ETA: 5s - loss: 2.0348 - accuracy: 0.5745 - auc: 0.6038 95/138 [===================>..........] - ETA: 5s - loss: 2.0403 - accuracy: 0.5737 - auc: 0.6005 96/138 [===================>..........] - ETA: 5s - loss: 2.0379 - accuracy: 0.5729 - auc: 0.6024 97/138 [====================>.........] - ETA: 5s - loss: 2.0318 - accuracy: 0.5773 - auc: 0.6075 98/138 [====================>.........] - ETA: 5s - loss: 2.0296 - accuracy: 0.5765 - auc: 0.6076 99/138 [====================>.........] - ETA: 4s - loss: 2.0258 - accuracy: 0.5808 - auc: 0.6097100/138 [====================>.........] - ETA: 4s - loss: 2.0219 - accuracy: 0.5850 - auc: 0.6118101/138 [====================>.........] - ETA: 4s - loss: 2.0277 - accuracy: 0.5842 - auc: 0.6092102/138 [=====================>........] - ETA: 4s - loss: 2.0352 - accuracy: 0.5833 - auc: 0.6043103/138 [=====================>........] - ETA: 4s - loss: 2.0331 - accuracy: 0.5825 - auc: 0.6052104/138 [=====================>........] - ETA: 4s - loss: 2.0271 - accuracy: 0.5865 - auc: 0.6103105/138 [=====================>........] - ETA: 4s - loss: 2.0230 - accuracy: 0.5905 - auc: 0.6127106/138 [======================>.......] - ETA: 4s - loss: 2.0250 - accuracy: 0.5849 - auc: 0.6094107/138 [======================>.......] - ETA: 3s - loss: 2.0240 - accuracy: 0.5841 - auc: 0.6099108/138 [======================>.......] - ETA: 3s - loss: 2.0228 - accuracy: 0.5833 - auc: 0.6101109/138 [======================>.......] - ETA: 3s - loss: 2.0309 - accuracy: 0.5826 - auc: 0.6050110/138 [======================>.......] - ETA: 3s - loss: 2.0369 - accuracy: 0.5818 - auc: 0.6024111/138 [=======================>......] - ETA: 3s - loss: 2.0338 - accuracy: 0.5811 - auc: 0.6047112/138 [=======================>......] - ETA: 3s - loss: 2.0274 - accuracy: 0.5848 - auc: 0.6107113/138 [=======================>......] - ETA: 3s - loss: 2.0328 - accuracy: 0.5841 - auc: 0.6078114/138 [=======================>......] - ETA: 3s - loss: 2.0300 - accuracy: 0.5833 - auc: 0.6099115/138 [========================>.....] - ETA: 2s - loss: 2.0254 - accuracy: 0.5870 - auc: 0.6135116/138 [========================>.....] - ETA: 2s - loss: 2.0254 - accuracy: 0.5862 - auc: 0.6127117/138 [========================>.....] - ETA: 2s - loss: 2.0242 - accuracy: 0.5855 - auc: 0.6134118/138 [========================>.....] - ETA: 2s - loss: 2.0215 - accuracy: 0.5847 - auc: 0.6145119/138 [========================>.....] - ETA: 2s - loss: 2.0299 - accuracy: 0.5840 - auc: 0.6109120/138 [=========================>....] - ETA: 2s - loss: 2.0272 - accuracy: 0.5833 - auc: 0.6125121/138 [=========================>....] - ETA: 2s - loss: 2.0363 - accuracy: 0.5785 - auc: 0.6052122/138 [=========================>....] - ETA: 2s - loss: 2.0343 - accuracy: 0.5779 - auc: 0.6067123/138 [=========================>....] - ETA: 1s - loss: 2.0294 - accuracy: 0.5813 - auc: 0.6105124/138 [=========================>....] - ETA: 1s - loss: 2.0293 - accuracy: 0.5806 - auc: 0.6098125/138 [==========================>...] - ETA: 1s - loss: 2.0360 - accuracy: 0.5760 - auc: 0.6048126/138 [==========================>...] - ETA: 1s - loss: 2.0330 - accuracy: 0.5794 - auc: 0.6064127/138 [==========================>...] - ETA: 1s - loss: 2.0383 - accuracy: 0.5787 - auc: 0.6034128/138 [==========================>...] - ETA: 1s - loss: 2.0398 - accuracy: 0.5781 - auc: 0.6020129/138 [===========================>..] - ETA: 1s - loss: 2.0410 - accuracy: 0.5775 - auc: 0.6001130/138 [===========================>..] - ETA: 1s - loss: 2.0437 - accuracy: 0.5731 - auc: 0.5968131/138 [===========================>..] - ETA: 0s - loss: 2.0421 - accuracy: 0.5725 - auc: 0.5973132/138 [===========================>..] - ETA: 0s - loss: 2.0380 - accuracy: 0.5758 - auc: 0.6003133/138 [===========================>..] - ETA: 0s - loss: 2.0371 - accuracy: 0.5752 - auc: 0.5996134/138 [============================>.] - ETA: 0s - loss: 2.0536 - accuracy: 0.5709 - auc: 0.5913135/138 [============================>.] - ETA: 0s - loss: 2.0519 - accuracy: 0.5704 - auc: 0.5914136/138 [============================>.] - ETA: 0s - loss: 2.0512 - accuracy: 0.5662 - auc: 0.5903137/138 [============================>.] - ETA: 0s - loss: 2.0476 - accuracy: 0.5693 - auc: 0.5926138/138 [==============================] - ETA: 0s - loss: 2.0455 - accuracy: 0.5688 - auc: 0.5937138/138 [==============================] - 20s 143ms/step - loss: 2.0455 - accuracy: 0.5688 - auc: 0.5937 - val_loss: 1.9706 - val_accuracy: 0.3623 - val_auc: 0.3111 - lr: 5.0000e-04
Best val_auc during training for fold 2: 0.3111
Final AUC for fold 2: 0.3957
Model: "model_3"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_4 (InputLayer)           [(None, 128, 128, 1  0           []                               
                                28, 1)]                                                           
                                                                                                  
 conv3d_45 (Conv3D)             (None, 128, 128, 12  448         ['input_4[0][0]']                
                                8, 16)                                                            
                                                                                                  
 batch_normalization_45 (BatchN  (None, 128, 128, 12  64         ['conv3d_45[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_45 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_45[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 conv3d_46 (Conv3D)             (None, 128, 128, 12  6928        ['leaky_re_lu_45[0][0]']         
                                8, 16)                                                            
                                                                                                  
 batch_normalization_46 (BatchN  (None, 128, 128, 12  64         ['conv3d_46[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_46 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_46[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 spatial_dropout3d_15 (SpatialD  (None, 128, 128, 12  0          ['leaky_re_lu_46[0][0]']         
 ropout3D)                      8, 16)                                                            
                                                                                                  
 conv3d_47 (Conv3D)             (None, 128, 128, 12  6928        ['spatial_dropout3d_15[0][0]']   
                                8, 16)                                                            
                                                                                                  
 batch_normalization_47 (BatchN  (None, 128, 128, 12  64         ['conv3d_47[0][0]']              
 ormalization)                  8, 16)                                                            
                                                                                                  
 leaky_re_lu_47 (LeakyReLU)     (None, 128, 128, 12  0           ['batch_normalization_47[0][0]'] 
                                8, 16)                                                            
                                                                                                  
 add_15 (Add)                   (None, 128, 128, 12  0           ['leaky_re_lu_47[0][0]',         
                                8, 16)                            'leaky_re_lu_45[0][0]']         
                                                                                                  
 conv3d_48 (Conv3D)             (None, 64, 64, 64,   13856       ['add_15[0][0]']                 
                                32)                                                               
                                                                                                  
 batch_normalization_48 (BatchN  (None, 64, 64, 64,   128        ['conv3d_48[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_48 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_48[0][0]'] 
                                32)                                                               
                                                                                                  
 conv3d_49 (Conv3D)             (None, 64, 64, 64,   27680       ['leaky_re_lu_48[0][0]']         
                                32)                                                               
                                                                                                  
 batch_normalization_49 (BatchN  (None, 64, 64, 64,   128        ['conv3d_49[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_49 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_49[0][0]'] 
                                32)                                                               
                                                                                                  
 spatial_dropout3d_16 (SpatialD  (None, 64, 64, 64,   0          ['leaky_re_lu_49[0][0]']         
 ropout3D)                      32)                                                               
                                                                                                  
 conv3d_50 (Conv3D)             (None, 64, 64, 64,   27680       ['spatial_dropout3d_16[0][0]']   
                                32)                                                               
                                                                                                  
 batch_normalization_50 (BatchN  (None, 64, 64, 64,   128        ['conv3d_50[0][0]']              
 ormalization)                  32)                                                               
                                                                                                  
 leaky_re_lu_50 (LeakyReLU)     (None, 64, 64, 64,   0           ['batch_normalization_50[0][0]'] 
                                32)                                                               
                                                                                                  
 add_16 (Add)                   (None, 64, 64, 64,   0           ['leaky_re_lu_50[0][0]',         
                                32)                               'leaky_re_lu_48[0][0]']         
                                                                                                  
 conv3d_51 (Conv3D)             (None, 32, 32, 32,   55360       ['add_16[0][0]']                 
                                64)                                                               
                                                                                                  
 batch_normalization_51 (BatchN  (None, 32, 32, 32,   256        ['conv3d_51[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_51 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_51[0][0]'] 
                                64)                                                               
                                                                                                  
 conv3d_52 (Conv3D)             (None, 32, 32, 32,   110656      ['leaky_re_lu_51[0][0]']         
                                64)                                                               
                                                                                                  
 batch_normalization_52 (BatchN  (None, 32, 32, 32,   256        ['conv3d_52[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_52 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_52[0][0]'] 
                                64)                                                               
                                                                                                  
 spatial_dropout3d_17 (SpatialD  (None, 32, 32, 32,   0          ['leaky_re_lu_52[0][0]']         
 ropout3D)                      64)                                                               
                                                                                                  
 conv3d_53 (Conv3D)             (None, 32, 32, 32,   110656      ['spatial_dropout3d_17[0][0]']   
                                64)                                                               
                                                                                                  
 batch_normalization_53 (BatchN  (None, 32, 32, 32,   256        ['conv3d_53[0][0]']              
 ormalization)                  64)                                                               
                                                                                                  
 leaky_re_lu_53 (LeakyReLU)     (None, 32, 32, 32,   0           ['batch_normalization_53[0][0]'] 
                                64)                                                               
                                                                                                  
 add_17 (Add)                   (None, 32, 32, 32,   0           ['leaky_re_lu_53[0][0]',         
                                64)                               'leaky_re_lu_51[0][0]']         
                                                                                                  
 conv3d_54 (Conv3D)             (None, 16, 16, 16,   221312      ['add_17[0][0]']                 
                                128)                                                              
                                                                                                  
 batch_normalization_54 (BatchN  (None, 16, 16, 16,   512        ['conv3d_54[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_54 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_54[0][0]'] 
                                128)                                                              
                                                                                                  
 conv3d_55 (Conv3D)             (None, 16, 16, 16,   442496      ['leaky_re_lu_54[0][0]']         
                                128)                                                              
                                                                                                  
 batch_normalization_55 (BatchN  (None, 16, 16, 16,   512        ['conv3d_55[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_55 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_55[0][0]'] 
                                128)                                                              
                                                                                                  
 spatial_dropout3d_18 (SpatialD  (None, 16, 16, 16,   0          ['leaky_re_lu_55[0][0]']         
 ropout3D)                      128)                                                              
                                                                                                  
 conv3d_56 (Conv3D)             (None, 16, 16, 16,   442496      ['spatial_dropout3d_18[0][0]']   
                                128)                                                              
                                                                                                  
 batch_normalization_56 (BatchN  (None, 16, 16, 16,   512        ['conv3d_56[0][0]']              
 ormalization)                  128)                                                              
                                                                                                  
 leaky_re_lu_56 (LeakyReLU)     (None, 16, 16, 16,   0           ['batch_normalization_56[0][0]'] 
                                128)                                                              
                                                                                                  
 add_18 (Add)                   (None, 16, 16, 16,   0           ['leaky_re_lu_56[0][0]',         
                                128)                              'leaky_re_lu_54[0][0]']         
                                                                                                  
 conv3d_57 (Conv3D)             (None, 8, 8, 8, 256  884992      ['add_18[0][0]']                 
                                )                                                                 
                                                                                                  
 batch_normalization_57 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_57[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_57 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_57[0][0]'] 
                                )                                                                 
                                                                                                  
 conv3d_58 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['leaky_re_lu_57[0][0]']         
                                )                                                                 
                                                                                                  
 batch_normalization_58 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_58[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_58 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_58[0][0]'] 
                                )                                                                 
                                                                                                  
 spatial_dropout3d_19 (SpatialD  (None, 8, 8, 8, 256  0          ['leaky_re_lu_58[0][0]']         
 ropout3D)                      )                                                                 
                                                                                                  
 conv3d_59 (Conv3D)             (None, 8, 8, 8, 256  1769728     ['spatial_dropout3d_19[0][0]']   
                                )                                                                 
                                                                                                  
 batch_normalization_59 (BatchN  (None, 8, 8, 8, 256  1024       ['conv3d_59[0][0]']              
 ormalization)                  )                                                                 
                                                                                                  
 leaky_re_lu_59 (LeakyReLU)     (None, 8, 8, 8, 256  0           ['batch_normalization_59[0][0]'] 
                                )                                                                 
                                                                                                  
 add_19 (Add)                   (None, 8, 8, 8, 256  0           ['leaky_re_lu_59[0][0]',         
                                )                                 'leaky_re_lu_57[0][0]']         
                                                                                                  
 global_average_pooling3d_3 (Gl  (None, 256)         0           ['add_19[0][0]']                 
 obalAveragePooling3D)                                                                            
                                                                                                  
 dropout_3 (Dropout)            (None, 256)          0           ['global_average_pooling3d_3[0][0
                                                                 ]']                              
                                                                                                  
 dense_3 (Dense)                (None, 2)            514         ['dropout_3[0][0]']              
                                                                                                  
==================================================================================================
Total params: 5,897,410
Trainable params: 5,894,434
Non-trainable params: 2,976
__________________________________________________________________________________________________
Epoch 1/2
  1/138 [..............................] - ETA: 4:25 - loss: 3.1492 - accuracy: 0.5000 - auc: 0.2500  2/138 [..............................] - ETA: 17s - loss: 2.9110 - accuracy: 0.5000 - auc: 0.2500   3/138 [..............................] - ETA: 17s - loss: 3.0658 - accuracy: 0.3333 - auc: 0.1111  4/138 [..............................] - ETA: 17s - loss: 3.8880 - accuracy: 0.2500 - auc: 0.0625  5/138 [>.............................] - ETA: 16s - loss: 3.4355 - accuracy: 0.4000 - auc: 0.2600  6/138 [>.............................] - ETA: 16s - loss: 3.4410 - accuracy: 0.3333 - auc: 0.2222  7/138 [>.............................] - ETA: 16s - loss: 3.1911 - accuracy: 0.3571 - auc: 0.2908  8/138 [>.............................] - ETA: 16s - loss: 3.0141 - accuracy: 0.3750 - auc: 0.3359  9/138 [>.............................] - ETA: 16s - loss: 2.9965 - accuracy: 0.3889 - auc: 0.3735 10/138 [=>............................] - ETA: 16s - loss: 2.9952 - accuracy: 0.4000 - auc: 0.4075 11/138 [=>............................] - ETA: 16s - loss: 2.8408 - accuracy: 0.4545 - auc: 0.5041 12/138 [=>............................] - ETA: 15s - loss: 2.7145 - accuracy: 0.5000 - auc: 0.5642 13/138 [=>............................] - ETA: 15s - loss: 2.7734 - accuracy: 0.5000 - auc: 0.5577 14/138 [==>...........................] - ETA: 15s - loss: 2.8504 - accuracy: 0.5000 - auc: 0.5421 15/138 [==>...........................] - ETA: 15s - loss: 2.7698 - accuracy: 0.5333 - auc: 0.5522 16/138 [==>...........................] - ETA: 15s - loss: 2.9130 - accuracy: 0.5000 - auc: 0.5029 17/138 [==>...........................] - ETA: 15s - loss: 2.9976 - accuracy: 0.4706 - auc: 0.4706 18/138 [==>...........................] - ETA: 15s - loss: 2.9275 - accuracy: 0.5000 - auc: 0.4799 19/138 [===>..........................] - ETA: 15s - loss: 2.9160 - accuracy: 0.4737 - auc: 0.4668 20/138 [===>..........................] - ETA: 14s - loss: 2.9244 - accuracy: 0.4750 - auc: 0.4594 21/138 [===>..........................] - ETA: 14s - loss: 3.0062 - accuracy: 0.4524 - auc: 0.4354 22/138 [===>..........................] - ETA: 14s - loss: 3.0265 - accuracy: 0.4318 - auc: 0.4215 23/138 [====>.........................] - ETA: 14s - loss: 2.9574 - accuracy: 0.4565 - auc: 0.4409 24/138 [====>.........................] - ETA: 14s - loss: 2.9492 - accuracy: 0.4583 - auc: 0.4366 25/138 [====>.........................] - ETA: 14s - loss: 2.9148 - accuracy: 0.4600 - auc: 0.4364 26/138 [====>.........................] - ETA: 14s - loss: 2.8804 - accuracy: 0.4615 - auc: 0.4393 27/138 [====>.........................] - ETA: 14s - loss: 2.8841 - accuracy: 0.4630 - auc: 0.4451 28/138 [=====>........................] - ETA: 13s - loss: 2.8591 - accuracy: 0.4643 - auc: 0.4582 29/138 [=====>........................] - ETA: 13s - loss: 2.8604 - accuracy: 0.4655 - auc: 0.4548 30/138 [=====>........................] - ETA: 13s - loss: 2.8713 - accuracy: 0.4667 - auc: 0.4522 31/138 [=====>........................] - ETA: 13s - loss: 2.8271 - accuracy: 0.4839 - auc: 0.4651 32/138 [=====>........................] - ETA: 13s - loss: 2.8086 - accuracy: 0.4844 - auc: 0.4651 33/138 [======>.......................] - ETA: 13s - loss: 2.7749 - accuracy: 0.5000 - auc: 0.4752 34/138 [======>.......................] - ETA: 13s - loss: 2.7397 - accuracy: 0.5147 - auc: 0.4851 35/138 [======>.......................] - ETA: 13s - loss: 2.7400 - accuracy: 0.5143 - auc: 0.4816 36/138 [======>.......................] - ETA: 12s - loss: 2.7017 - accuracy: 0.5278 - auc: 0.5017 37/138 [=======>......................] - ETA: 12s - loss: 2.6797 - accuracy: 0.5270 - auc: 0.5119 38/138 [=======>......................] - ETA: 12s - loss: 2.7170 - accuracy: 0.5132 - auc: 0.4971 39/138 [=======>......................] - ETA: 12s - loss: 2.6853 - accuracy: 0.5256 - auc: 0.5082 40/138 [=======>......................] - ETA: 12s - loss: 2.6709 - accuracy: 0.5250 - auc: 0.5159 41/138 [=======>......................] - ETA: 12s - loss: 2.6443 - accuracy: 0.5366 - auc: 0.5281 42/138 [========>.....................] - ETA: 12s - loss: 2.6352 - accuracy: 0.5357 - auc: 0.5259 43/138 [========>.....................] - ETA: 11s - loss: 2.6620 - accuracy: 0.5233 - auc: 0.5155 44/138 [========>.....................] - ETA: 11s - loss: 2.6365 - accuracy: 0.5341 - auc: 0.5236 45/138 [========>.....................] - ETA: 11s - loss: 2.6484 - accuracy: 0.5333 - auc: 0.5165 46/138 [=========>....................] - ETA: 11s - loss: 2.6393 - accuracy: 0.5326 - auc: 0.5171 47/138 [=========>....................] - ETA: 11s - loss: 2.6224 - accuracy: 0.5319 - auc: 0.5208 48/138 [=========>....................] - ETA: 11s - loss: 2.6045 - accuracy: 0.5417 - auc: 0.5247 49/138 [=========>....................] - ETA: 11s - loss: 2.5829 - accuracy: 0.5510 - auc: 0.5326 50/138 [=========>....................] - ETA: 11s - loss: 2.5626 - accuracy: 0.5600 - auc: 0.5399 51/138 [==========>...................] - ETA: 10s - loss: 2.5725 - accuracy: 0.5490 - auc: 0.5329 52/138 [==========>...................] - ETA: 10s - loss: 2.5567 - accuracy: 0.5481 - auc: 0.5380 53/138 [==========>...................] - ETA: 10s - loss: 2.5410 - accuracy: 0.5566 - auc: 0.5428 54/138 [==========>...................] - ETA: 10s - loss: 2.5412 - accuracy: 0.5556 - auc: 0.5402 55/138 [==========>...................] - ETA: 10s - loss: 2.5266 - accuracy: 0.5636 - auc: 0.5446 56/138 [===========>..................] - ETA: 10s - loss: 2.5140 - accuracy: 0.5625 - auc: 0.5509 57/138 [===========>..................] - ETA: 10s - loss: 2.4957 - accuracy: 0.5702 - auc: 0.5586 58/138 [===========>..................] - ETA: 10s - loss: 2.4841 - accuracy: 0.5690 - auc: 0.5615 59/138 [===========>..................] - ETA: 9s - loss: 2.4682 - accuracy: 0.5763 - auc: 0.5676  60/138 [============>.................] - ETA: 9s - loss: 2.4543 - accuracy: 0.5833 - auc: 0.5724 61/138 [============>.................] - ETA: 9s - loss: 2.4573 - accuracy: 0.5820 - auc: 0.5688 62/138 [============>.................] - ETA: 9s - loss: 2.4462 - accuracy: 0.5806 - auc: 0.5728 63/138 [============>.................] - ETA: 9s - loss: 2.4348 - accuracy: 0.5794 - auc: 0.5787 64/138 [============>.................] - ETA: 9s - loss: 2.4219 - accuracy: 0.5859 - auc: 0.5833 65/138 [=============>................] - ETA: 9s - loss: 2.4074 - accuracy: 0.5923 - auc: 0.5906 66/138 [=============>................] - ETA: 9s - loss: 2.3955 - accuracy: 0.5985 - auc: 0.5950 67/138 [=============>................] - ETA: 8s - loss: 2.4009 - accuracy: 0.5970 - auc: 0.5922 68/138 [=============>................] - ETA: 8s - loss: 2.4002 - accuracy: 0.5956 - auc: 0.5928 69/138 [==============>...............] - ETA: 8s - loss: 2.4022 - accuracy: 0.5942 - auc: 0.5910 70/138 [==============>...............] - ETA: 8s - loss: 2.3981 - accuracy: 0.5929 - auc: 0.5907 71/138 [==============>...............] - ETA: 8s - loss: 2.3904 - accuracy: 0.5915 - auc: 0.5940 72/138 [==============>...............] - ETA: 8s - loss: 2.3861 - accuracy: 0.5903 - auc: 0.5943 73/138 [==============>...............] - ETA: 8s - loss: 2.3749 - accuracy: 0.5959 - auc: 0.5987 74/138 [===============>..............] - ETA: 8s - loss: 2.3713 - accuracy: 0.5946 - auc: 0.5986 75/138 [===============>..............] - ETA: 7s - loss: 2.3828 - accuracy: 0.5867 - auc: 0.5918 76/138 [===============>..............] - ETA: 7s - loss: 2.3878 - accuracy: 0.5855 - auc: 0.5882 77/138 [===============>..............] - ETA: 7s - loss: 2.3929 - accuracy: 0.5779 - auc: 0.5825 78/138 [===============>..............] - ETA: 7s - loss: 2.4015 - accuracy: 0.5769 - auc: 0.5788 79/138 [================>.............] - ETA: 7s - loss: 2.4170 - accuracy: 0.5759 - auc: 0.5747 80/138 [================>.............] - ETA: 7s - loss: 2.4341 - accuracy: 0.5750 - auc: 0.5704 81/138 [================>.............] - ETA: 7s - loss: 2.4221 - accuracy: 0.5802 - auc: 0.5759 82/138 [================>.............] - ETA: 7s - loss: 2.4111 - accuracy: 0.5854 - auc: 0.5809 83/138 [=================>............] - ETA: 6s - loss: 2.4111 - accuracy: 0.5843 - auc: 0.5790 84/138 [=================>............] - ETA: 6s - loss: 2.4080 - accuracy: 0.5774 - auc: 0.5783 85/138 [=================>............] - ETA: 6s - loss: 2.4015 - accuracy: 0.5765 - auc: 0.5798 86/138 [=================>............] - ETA: 6s - loss: 2.3897 - accuracy: 0.5814 - auc: 0.5869 87/138 [=================>............] - ETA: 6s - loss: 2.3814 - accuracy: 0.5862 - auc: 0.5898 88/138 [==================>...........] - ETA: 6s - loss: 2.3756 - accuracy: 0.5852 - auc: 0.5910 89/138 [==================>...........] - ETA: 6s - loss: 2.3705 - accuracy: 0.5843 - auc: 0.5918 90/138 [==================>...........] - ETA: 6s - loss: 2.3734 - accuracy: 0.5833 - auc: 0.5897 91/138 [==================>...........] - ETA: 5s - loss: 2.3698 - accuracy: 0.5824 - auc: 0.5894 92/138 [===================>..........] - ETA: 5s - loss: 2.3627 - accuracy: 0.5870 - auc: 0.5918 93/138 [===================>..........] - ETA: 5s - loss: 2.3531 - accuracy: 0.5914 - auc: 0.5965 94/138 [===================>..........] - ETA: 5s - loss: 2.3438 - accuracy: 0.5957 - auc: 0.6015 95/138 [===================>..........] - ETA: 5s - loss: 2.3393 - accuracy: 0.6000 - auc: 0.6023 96/138 [===================>..........] - ETA: 5s - loss: 2.3347 - accuracy: 0.5990 - auc: 0.6032 97/138 [====================>.........] - ETA: 5s - loss: 2.3339 - accuracy: 0.5979 - auc: 0.6023 98/138 [====================>.........] - ETA: 5s - loss: 2.3355 - accuracy: 0.5969 - auc: 0.6000 99/138 [====================>.........] - ETA: 4s - loss: 2.3523 - accuracy: 0.5909 - auc: 0.5911100/138 [====================>.........] - ETA: 4s - loss: 2.3473 - accuracy: 0.5900 - auc: 0.5924101/138 [====================>.........] - ETA: 4s - loss: 2.3459 - accuracy: 0.5891 - auc: 0.5922102/138 [=====================>........] - ETA: 4s - loss: 2.3449 - accuracy: 0.5882 - auc: 0.5916103/138 [=====================>........] - ETA: 4s - loss: 2.3399 - accuracy: 0.5922 - auc: 0.5928104/138 [=====================>........] - ETA: 4s - loss: 2.3403 - accuracy: 0.5913 - auc: 0.5907105/138 [=====================>........] - ETA: 4s - loss: 2.3368 - accuracy: 0.5905 - auc: 0.5912106/138 [======================>.......] - ETA: 4s - loss: 2.3403 - accuracy: 0.5849 - auc: 0.5873107/138 [======================>.......] - ETA: 3s - loss: 2.3367 - accuracy: 0.5841 - auc: 0.5878108/138 [======================>.......] - ETA: 3s - loss: 2.3366 - accuracy: 0.5787 - auc: 0.5860109/138 [======================>.......] - ETA: 3s - loss: 2.3288 - accuracy: 0.5826 - auc: 0.5897110/138 [======================>.......] - ETA: 3s - loss: 2.3213 - accuracy: 0.5864 - auc: 0.5938111/138 [=======================>......] - ETA: 3s - loss: 2.3145 - accuracy: 0.5901 - auc: 0.5974112/138 [=======================>......] - ETA: 3s - loss: 2.3107 - accuracy: 0.5893 - auc: 0.5986113/138 [=======================>......] - ETA: 3s - loss: 2.3082 - accuracy: 0.5885 - auc: 0.5994114/138 [=======================>......] - ETA: 3s - loss: 2.3017 - accuracy: 0.5921 - auc: 0.6024115/138 [========================>.....] - ETA: 2s - loss: 2.2974 - accuracy: 0.5913 - auc: 0.6042116/138 [========================>.....] - ETA: 2s - loss: 2.2924 - accuracy: 0.5905 - auc: 0.6062117/138 [========================>.....] - ETA: 2s - loss: 2.2934 - accuracy: 0.5897 - auc: 0.6038118/138 [========================>.....] - ETA: 2s - loss: 2.2865 - accuracy: 0.5932 - auc: 0.6075119/138 [========================>.....] - ETA: 2s - loss: 2.2802 - accuracy: 0.5966 - auc: 0.6114120/138 [=========================>....] - ETA: 2s - loss: 2.2744 - accuracy: 0.6000 - auc: 0.6143121/138 [=========================>....] - ETA: 2s - loss: 2.2770 - accuracy: 0.5950 - auc: 0.6111122/138 [=========================>....] - ETA: 2s - loss: 2.2781 - accuracy: 0.5943 - auc: 0.6094123/138 [=========================>....] - ETA: 1s - loss: 2.2725 - accuracy: 0.5976 - auc: 0.6120124/138 [=========================>....] - ETA: 1s - loss: 2.2776 - accuracy: 0.5927 - auc: 0.6075125/138 [==========================>...] - ETA: 1s - loss: 2.2718 - accuracy: 0.5960 - auc: 0.6113126/138 [==========================>...] - ETA: 1s - loss: 2.2655 - accuracy: 0.5992 - auc: 0.6151127/138 [==========================>...] - ETA: 1s - loss: 2.2653 - accuracy: 0.5984 - auc: 0.6142128/138 [==========================>...] - ETA: 1s - loss: 2.2602 - accuracy: 0.6016 - auc: 0.6167129/138 [===========================>..] - ETA: 1s - loss: 2.2546 - accuracy: 0.6047 - auc: 0.6197130/138 [===========================>..] - ETA: 1s - loss: 2.2483 - accuracy: 0.6077 - auc: 0.6232131/138 [===========================>..] - ETA: 0s - loss: 2.2548 - accuracy: 0.6031 - auc: 0.6189132/138 [===========================>..] - ETA: 0s - loss: 2.2491 - accuracy: 0.6061 - auc: 0.6222133/138 [===========================>..] - ETA: 0s - loss: 2.2523 - accuracy: 0.6053 - auc: 0.6192134/138 [============================>.] - ETA: 0s - loss: 2.2555 - accuracy: 0.6045 - auc: 0.6171135/138 [============================>.] - ETA: 0s - loss: 2.2567 - accuracy: 0.6037 - auc: 0.6154136/138 [============================>.] - ETA: 0s - loss: 2.2583 - accuracy: 0.6029 - auc: 0.6137137/138 [============================>.] - ETA: 0s - loss: 2.2555 - accuracy: 0.6022 - auc: 0.6148138/138 [==============================] - ETA: 0s - loss: 2.2503 - accuracy: 0.6051 - auc: 0.6177138/138 [==============================] - 23s 156ms/step - loss: 2.2503 - accuracy: 0.6051 - auc: 0.6177 - val_loss: 2.2981 - val_accuracy: 0.3696 - val_auc: 0.2222 - lr: 5.0000e-04
Epoch 2/2
  1/138 [..............................] - ETA: 17s - loss: 1.6744 - accuracy: 1.0000 - auc: 1.0000  2/138 [..............................] - ETA: 17s - loss: 2.0587 - accuracy: 0.7500 - auc: 0.5625  3/138 [..............................] - ETA: 17s - loss: 1.8629 - accuracy: 0.8333 - auc: 0.7500  4/138 [..............................] - ETA: 16s - loss: 1.8292 - accuracy: 0.7500 - auc: 0.8125  5/138 [>.............................] - ETA: 16s - loss: 1.7416 - accuracy: 0.8000 - auc: 0.8800  6/138 [>.............................] - ETA: 16s - loss: 1.6724 - accuracy: 0.8333 - auc: 0.9167  7/138 [>.............................] - ETA: 16s - loss: 1.9880 - accuracy: 0.7143 - auc: 0.7551  8/138 [>.............................] - ETA: 16s - loss: 2.1402 - accuracy: 0.6875 - auc: 0.6836  9/138 [>.............................] - ETA: 16s - loss: 2.0727 - accuracy: 0.7222 - auc: 0.7130 10/138 [=>............................] - ETA: 16s - loss: 2.1549 - accuracy: 0.7000 - auc: 0.6700 11/138 [=>............................] - ETA: 16s - loss: 2.1187 - accuracy: 0.7273 - auc: 0.6860 12/138 [=>............................] - ETA: 15s - loss: 2.2024 - accuracy: 0.6667 - auc: 0.6389 13/138 [=>............................] - ETA: 15s - loss: 2.2103 - accuracy: 0.6154 - auc: 0.6228 14/138 [==>...........................] - ETA: 15s - loss: 2.2625 - accuracy: 0.5714 - auc: 0.5931 15/138 [==>...........................] - ETA: 15s - loss: 2.3008 - accuracy: 0.5333 - auc: 0.5633 16/138 [==>...........................] - ETA: 15s - loss: 2.2515 - accuracy: 0.5625 - auc: 0.5928 17/138 [==>...........................] - ETA: 15s - loss: 2.2243 - accuracy: 0.5588 - auc: 0.6038 18/138 [==>...........................] - ETA: 15s - loss: 2.2035 - accuracy: 0.5556 - auc: 0.6088 19/138 [===>..........................] - ETA: 15s - loss: 2.2044 - accuracy: 0.5526 - auc: 0.6108 20/138 [===>..........................] - ETA: 14s - loss: 2.2582 - accuracy: 0.5500 - auc: 0.5831 21/138 [===>..........................] - ETA: 14s - loss: 2.2227 - accuracy: 0.5714 - auc: 0.6026 22/138 [===>..........................] - ETA: 14s - loss: 2.1946 - accuracy: 0.5909 - auc: 0.6152 23/138 [====>.........................] - ETA: 14s - loss: 2.1722 - accuracy: 0.6087 - auc: 0.6252 24/138 [====>.........................] - ETA: 14s - loss: 2.1532 - accuracy: 0.6250 - auc: 0.6341 25/138 [====>.........................] - ETA: 14s - loss: 2.1768 - accuracy: 0.6000 - auc: 0.6140 26/138 [====>.........................] - ETA: 14s - loss: 2.1506 - accuracy: 0.6154 - auc: 0.6328 27/138 [====>.........................] - ETA: 14s - loss: 2.1849 - accuracy: 0.5926 - auc: 0.6049 28/138 [=====>........................] - ETA: 13s - loss: 2.2268 - accuracy: 0.5893 - auc: 0.5906 29/138 [=====>........................] - ETA: 13s - loss: 2.2254 - accuracy: 0.5862 - auc: 0.5865 30/138 [=====>........................] - ETA: 13s - loss: 2.2041 - accuracy: 0.6000 - auc: 0.5964 31/138 [=====>........................] - ETA: 13s - loss: 2.1978 - accuracy: 0.5968 - auc: 0.5965 32/138 [=====>........................] - ETA: 13s - loss: 2.2014 - accuracy: 0.5938 - auc: 0.5945 33/138 [======>.......................] - ETA: 13s - loss: 2.1985 - accuracy: 0.5909 - auc: 0.5923 34/138 [======>.......................] - ETA: 13s - loss: 2.1838 - accuracy: 0.6029 - auc: 0.5984 35/138 [======>.......................] - ETA: 13s - loss: 2.1861 - accuracy: 0.5857 - auc: 0.5927 36/138 [======>.......................] - ETA: 12s - loss: 2.1969 - accuracy: 0.5694 - auc: 0.5810 37/138 [=======>......................] - ETA: 12s - loss: 2.1756 - accuracy: 0.5811 - auc: 0.5975 38/138 [=======>......................] - ETA: 12s - loss: 2.1665 - accuracy: 0.5921 - auc: 0.5994 39/138 [=======>......................] - ETA: 12s - loss: 2.1691 - accuracy: 0.5897 - auc: 0.5925 40/138 [=======>......................] - ETA: 12s - loss: 2.1783 - accuracy: 0.5875 - auc: 0.5831 41/138 [=======>......................] - ETA: 12s - loss: 2.1700 - accuracy: 0.5854 - auc: 0.5864 42/138 [========>.....................] - ETA: 12s - loss: 2.1785 - accuracy: 0.5833 - auc: 0.5785 43/138 [========>.....................] - ETA: 11s - loss: 2.1701 - accuracy: 0.5814 - auc: 0.5825 44/138 [========>.....................] - ETA: 11s - loss: 2.1573 - accuracy: 0.5909 - auc: 0.5908 45/138 [========>.....................] - ETA: 11s - loss: 2.1568 - accuracy: 0.5889 - auc: 0.5872 46/138 [=========>....................] - ETA: 11s - loss: 2.1536 - accuracy: 0.5870 - auc: 0.5854 47/138 [=========>....................] - ETA: 11s - loss: 2.1424 - accuracy: 0.5957 - auc: 0.5934 48/138 [=========>....................] - ETA: 11s - loss: 2.1266 - accuracy: 0.6042 - auc: 0.6058 49/138 [=========>....................] - ETA: 11s - loss: 2.1203 - accuracy: 0.6020 - auc: 0.6077 50/138 [=========>....................] - ETA: 11s - loss: 2.1185 - accuracy: 0.6000 - auc: 0.6087 51/138 [==========>...................] - ETA: 10s - loss: 2.1070 - accuracy: 0.6078 - auc: 0.6166 52/138 [==========>...................] - ETA: 10s - loss: 2.1149 - accuracy: 0.6058 - auc: 0.6110 53/138 [==========>...................] - ETA: 10s - loss: 2.1040 - accuracy: 0.6132 - auc: 0.6192 54/138 [==========>...................] - ETA: 10s - loss: 2.0916 - accuracy: 0.6204 - auc: 0.6287 55/138 [==========>...................] - ETA: 10s - loss: 2.0867 - accuracy: 0.6182 - auc: 0.6307 56/138 [===========>..................] - ETA: 10s - loss: 2.0830 - accuracy: 0.6161 - auc: 0.6315 57/138 [===========>..................] - ETA: 10s - loss: 2.0814 - accuracy: 0.6053 - auc: 0.6299 58/138 [===========>..................] - ETA: 10s - loss: 2.0794 - accuracy: 0.6034 - auc: 0.6289 59/138 [===========>..................] - ETA: 9s - loss: 2.1031 - accuracy: 0.6017 - auc: 0.6217  60/138 [============>.................] - ETA: 9s - loss: 2.1162 - accuracy: 0.5917 - auc: 0.6115 61/138 [============>.................] - ETA: 9s - loss: 2.1098 - accuracy: 0.5984 - auc: 0.6149 62/138 [============>.................] - ETA: 9s - loss: 2.1103 - accuracy: 0.5968 - auc: 0.6143 63/138 [============>.................] - ETA: 9s - loss: 2.1063 - accuracy: 0.5952 - auc: 0.6153 64/138 [============>.................] - ETA: 9s - loss: 2.1098 - accuracy: 0.5938 - auc: 0.6135 65/138 [=============>................] - ETA: 9s - loss: 2.1064 - accuracy: 0.5923 - auc: 0.6136 66/138 [=============>................] - ETA: 9s - loss: 2.1122 - accuracy: 0.5833 - auc: 0.6072 67/138 [=============>................] - ETA: 8s - loss: 2.1058 - accuracy: 0.5896 - auc: 0.6110 68/138 [=============>................] - ETA: 8s - loss: 2.0971 - accuracy: 0.5956 - auc: 0.6182 69/138 [==============>...............] - ETA: 8s - loss: 2.0921 - accuracy: 0.5942 - auc: 0.6216 70/138 [==============>...............] - ETA: 8s - loss: 2.1416 - accuracy: 0.5929 - auc: 0.6175 71/138 [==============>...............] - ETA: 8s - loss: 2.1480 - accuracy: 0.5915 - auc: 0.6141 72/138 [==============>...............] - ETA: 8s - loss: 2.1623 - accuracy: 0.5903 - auc: 0.6104 73/138 [==============>...............] - ETA: 8s - loss: 2.1787 - accuracy: 0.5822 - auc: 0.5999 74/138 [===============>..............] - ETA: 8s - loss: 2.1798 - accuracy: 0.5811 - auc: 0.5965 75/138 [===============>..............] - ETA: 7s - loss: 2.1814 - accuracy: 0.5733 - auc: 0.5919 76/138 [===============>..............] - ETA: 7s - loss: 2.1886 - accuracy: 0.5724 - auc: 0.5891 77/138 [===============>..............] - ETA: 7s - loss: 2.1879 - accuracy: 0.5714 - auc: 0.5871 78/138 [===============>..............] - ETA: 7s - loss: 2.1810 - accuracy: 0.5705 - auc: 0.5911 79/138 [================>.............] - ETA: 7s - loss: 2.1918 - accuracy: 0.5696 - auc: 0.5853 80/138 [================>.............] - ETA: 7s - loss: 2.1908 - accuracy: 0.5688 - auc: 0.5842 81/138 [================>.............] - ETA: 7s - loss: 2.1887 - accuracy: 0.5679 - auc: 0.5846 82/138 [================>.............] - ETA: 7s - loss: 2.1845 - accuracy: 0.5671 - auc: 0.5860 83/138 [=================>............] - ETA: 6s - loss: 2.1838 - accuracy: 0.5663 - auc: 0.5861 84/138 [=================>............] - ETA: 6s - loss: 2.1971 - accuracy: 0.5655 - auc: 0.5827 85/138 [=================>............] - ETA: 6s - loss: 2.1954 - accuracy: 0.5647 - auc: 0.5825 86/138 [=================>............] - ETA: 6s - loss: 2.1974 - accuracy: 0.5640 - auc: 0.5789 87/138 [=================>............] - ETA: 6s - loss: 2.2119 - accuracy: 0.5575 - auc: 0.5713 88/138 [==================>...........] - ETA: 6s - loss: 2.2078 - accuracy: 0.5625 - auc: 0.5721 89/138 [==================>...........] - ETA: 6s - loss: 2.2083 - accuracy: 0.5618 - auc: 0.5713 90/138 [==================>...........] - ETA: 6s - loss: 2.2030 - accuracy: 0.5667 - auc: 0.5737 91/138 [==================>...........] - ETA: 5s - loss: 2.1979 - accuracy: 0.5659 - auc: 0.5759 92/138 [===================>..........] - ETA: 5s - loss: 2.2028 - accuracy: 0.5598 - auc: 0.5707 93/138 [===================>..........] - ETA: 5s - loss: 2.2018 - accuracy: 0.5591 - auc: 0.5702 94/138 [===================>..........] - ETA: 5s - loss: 2.2001 - accuracy: 0.5585 - auc: 0.5691 95/138 [===================>..........] - ETA: 5s - loss: 2.1949 - accuracy: 0.5632 - auc: 0.5716 96/138 [===================>..........] - ETA: 5s - loss: 2.1864 - accuracy: 0.5677 - auc: 0.5784 97/138 [====================>.........] - ETA: 5s - loss: 2.1911 - accuracy: 0.5619 - auc: 0.5732 98/138 [====================>.........] - ETA: 5s - loss: 2.1901 - accuracy: 0.5612 - auc: 0.5717 99/138 [====================>.........] - ETA: 4s - loss: 2.1892 - accuracy: 0.5606 - auc: 0.5701100/138 [====================>.........] - ETA: 4s - loss: 2.1817 - accuracy: 0.5650 - auc: 0.5757101/138 [====================>.........] - ETA: 4s - loss: 2.1748 - accuracy: 0.5693 - auc: 0.5809102/138 [=====================>........] - ETA: 4s - loss: 2.1670 - accuracy: 0.5735 - auc: 0.5868103/138 [=====================>........] - ETA: 4s - loss: 2.1819 - accuracy: 0.5680 - auc: 0.5809104/138 [=====================>........] - ETA: 4s - loss: 2.1770 - accuracy: 0.5721 - auc: 0.5833105/138 [=====================>........] - ETA: 4s - loss: 2.1761 - accuracy: 0.5714 - auc: 0.5834106/138 [======================>.......] - ETA: 4s - loss: 2.1759 - accuracy: 0.5708 - auc: 0.5818107/138 [======================>.......] - ETA: 3s - loss: 2.1711 - accuracy: 0.5748 - auc: 0.5844108/138 [======================>.......] - ETA: 3s - loss: 2.1797 - accuracy: 0.5741 - auc: 0.5824109/138 [======================>.......] - ETA: 3s - loss: 2.1816 - accuracy: 0.5734 - auc: 0.5795110/138 [======================>.......] - ETA: 3s - loss: 2.1887 - accuracy: 0.5682 - auc: 0.5741111/138 [=======================>......] - ETA: 3s - loss: 2.1843 - accuracy: 0.5676 - auc: 0.5768112/138 [=======================>......] - ETA: 3s - loss: 2.1898 - accuracy: 0.5625 - auc: 0.5711113/138 [=======================>......] - ETA: 3s - loss: 2.1859 - accuracy: 0.5664 - auc: 0.5726114/138 [=======================>......] - ETA: 3s - loss: 2.1905 - accuracy: 0.5614 - auc: 0.5675115/138 [========================>.....] - ETA: 2s - loss: 2.1907 - accuracy: 0.5565 - auc: 0.5650116/138 [========================>.....] - ETA: 2s - loss: 2.1897 - accuracy: 0.5560 - auc: 0.5647117/138 [========================>.....] - ETA: 2s - loss: 2.1866 - accuracy: 0.5556 - auc: 0.5654118/138 [========================>.....] - ETA: 2s - loss: 2.1845 - accuracy: 0.5551 - auc: 0.5656119/138 [========================>.....] - ETA: 2s - loss: 2.1829 - accuracy: 0.5546 - auc: 0.5650120/138 [=========================>....] - ETA: 2s - loss: 2.1799 - accuracy: 0.5542 - auc: 0.5662121/138 [=========================>....] - ETA: 2s - loss: 2.1789 - accuracy: 0.5537 - auc: 0.5656122/138 [=========================>....] - ETA: 2s - loss: 2.1757 - accuracy: 0.5533 - auc: 0.5666123/138 [=========================>....] - ETA: 1s - loss: 2.1724 - accuracy: 0.5528 - auc: 0.5683124/138 [=========================>....] - ETA: 1s - loss: 2.1775 - accuracy: 0.5484 - auc: 0.5631125/138 [==========================>...] - ETA: 1s - loss: 2.1766 - accuracy: 0.5440 - auc: 0.5616126/138 [==========================>...] - ETA: 1s - loss: 2.1715 - accuracy: 0.5476 - auc: 0.5651127/138 [==========================>...] - ETA: 1s - loss: 2.1716 - accuracy: 0.5472 - auc: 0.5647128/138 [==========================>...] - ETA: 1s - loss: 2.1777 - accuracy: 0.5430 - auc: 0.5608129/138 [===========================>..] - ETA: 1s - loss: 2.1734 - accuracy: 0.5465 - auc: 0.5634130/138 [===========================>..] - ETA: 1s - loss: 2.1702 - accuracy: 0.5500 - auc: 0.5647131/138 [===========================>..] - ETA: 0s - loss: 2.1675 - accuracy: 0.5496 - auc: 0.5659132/138 [===========================>..] - ETA: 0s - loss: 2.1641 - accuracy: 0.5492 - auc: 0.5677133/138 [===========================>..] - ETA: 0s - loss: 2.1603 - accuracy: 0.5526 - auc: 0.5699134/138 [============================>.] - ETA: 0s - loss: 2.1535 - accuracy: 0.5560 - auc: 0.5759135/138 [============================>.] - ETA: 0s - loss: 2.1508 - accuracy: 0.5593 - auc: 0.5768136/138 [============================>.] - ETA: 0s - loss: 2.1471 - accuracy: 0.5588 - auc: 0.5791137/138 [============================>.] - ETA: 0s - loss: 2.1436 - accuracy: 0.5584 - auc: 0.5811138/138 [==============================] - ETA: 0s - loss: 2.1403 - accuracy: 0.5580 - auc: 0.5828138/138 [==============================] - 20s 144ms/step - loss: 2.1403 - accuracy: 0.5580 - auc: 0.5828 - val_loss: 2.7060 - val_accuracy: 0.6304 - val_auc: 0.7588 - lr: 5.0000e-04
Best val_auc during training for fold 3: 0.7588
Final AUC for fold 3: 0.8555
Loss vs Validation Loss plot (0-1 range) saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/loss_vs_val_loss_zoomed_0_to_1.png
Average AUC across all folds: 0.6266
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_1.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_1_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_1.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_1_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_2.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_2_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_2.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_2_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_3.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_3_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_3.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_3_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_4.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_4_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_4.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_4_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_5.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_5_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_5.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_5_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_6.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_6_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_6.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_6_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_7.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_7_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_7.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_7_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_8.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_8_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_8.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_8_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_9.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_9_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_9.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_9_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_10.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_10_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_10.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_10_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_11.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_11_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_11.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_11_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_12.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_12_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_12.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_12_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_13.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_13_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_13.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_13_class1.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class0_conv3d_14.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_14_class0.png
3D Grad-CAM heatmap saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/gradcam_cd_MRI_class1_conv3d_14.nii.gz
Glass brain plot saved at ./grad-cam/5_context_from_16_0.5_dropout_1e3/cd/MRI/glass_brain_cd_MRI_conv3d_14_class1.png
--------------------------------------------------------------
Begin Slurm Epilogue Sun Sep 15 12:51:18 CDT 2024 1726422678
Name                : cd-MRI-train
User                : l.peiwang
Partition           : tier2_gpu
Nodes               : gpua404
Cores               : 2
State               : COMPLETED
Submit              : 2024-09-15T11:57:56
Start               : 2024-09-15T11:57:57
End                 : 2024-09-15T12:51:16
Reserved Walltime   : 5-10:50:00
Used Walltime       :   00:53:19
Used CPU Time       :   00:49:41
% User (Computation): 98.83%
% System (I/O)      :  1.17%
Mem Reserved        : 500000M
Max Mem Used        : 37.41G (40170242048.0)
Max Disk Write      : 81.25M (85196800.0)
Max Disk Read       : 5.63G (6048133939.2)
Max-Mem-Used Node   : gpua404
Max-Disk-Write Node : gpua404
Max-Disk-Read Node  : gpua404
NVIDIA A100-SXM4-40GB
Error: Unable to retrieve job statistics. Return: No data is available.
End Slurm Epilogue Sun Sep 15 12:51:18 CDT 2024 1726422678
--------------------------------------------------------------
