{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55310610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "import glob\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy.ndimage as ndi\n",
    "import statsmodels.stats.contingency_tables as ct\n",
    "import time\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nilearn import image, plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.masking import (apply_mask, compute_brain_mask,\n",
    "                             compute_multi_brain_mask, intersect_masks, unmask)\n",
    "from nilearn.plotting import plot_roi, plot_stat_map, show\n",
    "from numpy import mean, std\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import chi2_contingency, norm\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix,\n",
    "                             precision_recall_curve, precision_recall_fscore_support,\n",
    "                             roc_auc_score, roc_curve,balanced_accuracy_score,precision_score,recall_score,f1_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, StratifiedKFold,\n",
    "                                     cross_val_predict, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import Binarizer, label_binarize\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import auc as calculate_auc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils import (\n",
    "    compute_kernel_matrix,\n",
    "    linear_kernel,\n",
    "    min_max_normalization,\n",
    "    compute_p_values,\n",
    "    compute_weights_for_linear_kernel,\n",
    "    compute_covariance_directly,\n",
    "    compute_p_values_with_correction,\n",
    "    normalize_features,\n",
    "    apply_normalization,\n",
    "    compute_bootstrap_confi\n",
    "\n",
    ")\n",
    "\n",
    "from plot_utils import (\n",
    "    plot_roc_curve,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "def compute_auprc(y_true, y_pred_probs):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_probs)\n",
    "    sorted_indices = np.argsort(recall)\n",
    "    sorted_recall = recall[sorted_indices]\n",
    "    sorted_precision = precision[sorted_indices]\n",
    "    unique_recall, unique_indices = np.unique(sorted_recall, return_index=True)\n",
    "    unique_precision = np.array([max(sorted_precision[:i + 1]) for i in unique_indices])\n",
    "    return calculate_auc(unique_recall, unique_precision)\n",
    "\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_visual_cov_V3(data, label, randomseed, outer, inner, num_permutations):\n",
    "    train_data = data\n",
    "    train_label = label\n",
    "    random_states = randomseed\n",
    "    \n",
    "    all_aucs = []\n",
    "    all_single_weights = []\n",
    "    all_corrected_weights = []\n",
    "    all_p_values_single = []\n",
    "    all_p_values_corrected = []\n",
    "    \n",
    "    for rs in random_states:\n",
    "        print(f\"Running outer loop with random state: {rs}\")\n",
    "        cv_outer = StratifiedKFold(n_splits=outer, shuffle=True, random_state=rs)\n",
    "        \n",
    "        for train_ix, test_ix in cv_outer.split(train_data, train_label):\n",
    "            X_train, X_test = train_data[train_ix, :], train_data[test_ix, :]\n",
    "            y_train, y_test = np.array(train_label)[train_ix], np.array(train_label)[test_ix]\n",
    "            \n",
    "            # Normalize the training data based on control indices within this fold\n",
    "            control_indices_train = [i for i, label in enumerate(y_train) if label == 0]\n",
    "            X_train, normalization_params = normalize_features(X_train, control_indices_train, return_params=True)\n",
    "            \n",
    "            # Normalize the test data using the same normalization parameters\n",
    "            X_test = apply_normalization(X_test, normalization_params)\n",
    "            \n",
    "            # Compute kernel matrices for both training and test data\n",
    "            K_train = compute_kernel_matrix(X_train, X_train, linear_kernel)\n",
    "            K_test = compute_kernel_matrix(X_test, X_train, linear_kernel)\n",
    "\n",
    "            cv_inner = StratifiedKFold(n_splits=inner, shuffle=True, random_state=1)\n",
    "            model = SVC(kernel=\"precomputed\", class_weight='balanced', probability=True)\n",
    "            space = dict()\n",
    "            space['C'] = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "            search = GridSearchCV(model, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "            result = search.fit(K_train, y_train)\n",
    "            best_model = result.best_estimator_\n",
    "\n",
    "            yhat = best_model.predict_proba(K_test)\n",
    "            yhat = yhat[:, 1]\n",
    "            auc = roc_auc_score(y_test, yhat)\n",
    "            all_aucs.append(auc)\n",
    "\n",
    "            X_support = X_train[best_model.support_, :]\n",
    "            single_weights = abs(compute_weights_for_linear_kernel(best_model, X_support))\n",
    "            single_weights = min_max_normalization(single_weights)\n",
    "            all_single_weights.append(single_weights)\n",
    "            p_values_single = compute_p_values(X_train, K_train, y_train, best_model, num_permutations)\n",
    "            all_p_values_single.append(p_values_single)\n",
    "\n",
    "            corrected_weights = compute_covariance_directly(X_train, y_train)\n",
    "            all_corrected_weights.append(corrected_weights)\n",
    "            p_values_corrected = compute_p_values_with_correction(X_train, K_train,y_train, best_model, num_permutations)\n",
    "            all_p_values_corrected.append(p_values_corrected)\n",
    "\n",
    "    average_single_weights = np.mean(all_single_weights, axis=0)\n",
    "    average_corrected_weights = np.mean(all_corrected_weights, axis=0)\n",
    "    average_p_values_single = np.mean(all_p_values_single, axis=0)\n",
    "    average_p_values_corrected = np.mean(all_p_values_corrected, axis=0)\n",
    "\n",
    "    print(f\"Average outer loop performance (AUC): {np.mean(all_aucs)}\")\n",
    "\n",
    "    return (\n",
    "        average_single_weights,\n",
    "        average_corrected_weights,\n",
    "        average_p_values_single,\n",
    "        average_p_values_corrected\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def nested_crossvalidation(data, label, method, task):\n",
    "\n",
    "    train_data = data\n",
    "    train_label = label\n",
    "    random_states = [10]\n",
    "    \n",
    "    all_y_test = []\n",
    "    all_y_prob = []\n",
    "    all_predictions = []\n",
    "    performance_dict = {}\n",
    "\n",
    "    tasks_dict = {\n",
    "        'cd': ('AD', 'CN'),\n",
    "        'dm': ('AD', 'MCI'),\n",
    "        'cm': ('MCI', 'CN'),\n",
    "        'pc': ('Preclinical', 'CN')\n",
    "    }\n",
    "    \n",
    "    positive, negative = tasks_dict[task]\n",
    "    for rs in random_states:\n",
    "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "        \n",
    "        for train_ix, test_ix in cv_outer.split(train_data, train_label):\n",
    "            X_train, X_test = train_data[train_ix, :], train_data[test_ix, :]\n",
    "            y_train, y_test = np.array(train_label)[train_ix], np.array(train_label)[test_ix]\n",
    "            \n",
    "            # Normalize the training data based on control indices within this fold\n",
    "            control_indices_train = [i for i, label in enumerate(y_train) if label == 0]\n",
    "            X_train, normalization_params = normalize_features(X_train, control_indices_train, return_params=True)\n",
    "            \n",
    "            # Normalize the test data using the same normalization parameters\n",
    "            X_test = apply_normalization(X_test, normalization_params)\n",
    "            \n",
    "            # Compute kernel matrices for both training and test data\n",
    "            print(X_train)\n",
    "            print(X_test)\n",
    "            K_train = compute_kernel_matrix(X_train, X_train, linear_kernel)\n",
    "            K_test = compute_kernel_matrix(X_test, X_train, linear_kernel)\n",
    "            cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "            model = SVC(kernel=\"precomputed\", class_weight='balanced', probability=True)\n",
    "            space = {'C': [1, 100, 10, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    "            search = GridSearchCV(model, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "            result = search.fit(K_train, y_train)\n",
    "            best_model = result.best_estimator_\n",
    "            yhat = best_model.predict_proba(K_test)\n",
    "            yhat = yhat[:, 1]\n",
    "            \n",
    "            all_y_test.extend(y_test.tolist())\n",
    "            all_y_prob.extend(yhat.tolist())\n",
    "            all_predictions.extend(best_model.predict(K_test).tolist())\n",
    "\n",
    "            for params, mean_score, std_score in zip(search.cv_results_['params'], \n",
    "                                                      search.cv_results_['mean_test_score'], \n",
    "                                                      search.cv_results_['std_test_score']):\n",
    "                C_value = params['C']\n",
    "                if C_value not in performance_dict:\n",
    "                    performance_dict[C_value] = {'mean_scores': [], 'std_scores': []}\n",
    "                performance_dict[C_value]['mean_scores'].append(mean_score)\n",
    "                performance_dict[C_value]['std_scores'].append(std_score)\n",
    "\n",
    "    auc = roc_auc_score(all_y_test, all_y_prob)\n",
    "    accuracy = accuracy_score(all_y_test, all_predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle UndefinedMetricWarning by setting zero_division=1\n",
    "    precision_classwise = precision_score(all_y_test, all_predictions, average=None, zero_division=1)\n",
    "    recall_classwise = recall_score(all_y_test, all_predictions, average=None)\n",
    "    f1_classwise = f1_score(all_y_test, all_predictions, average=None)\n",
    "\n",
    "    auprc = compute_auprc(all_y_test, all_y_prob)\n",
    "  \n",
    "    ppv = precision_classwise  # since they are the same, no need to compute twice\n",
    "    \n",
    "    cm = confusion_matrix(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle RuntimeWarning by checking for zero denominator\n",
    "    denominator = cm[1,1] + cm[0,1]\n",
    "    npv = cm[1,1] / denominator if denominator != 0 else 0\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "    \n",
    "    # 2. Compute bootstrap confidence intervals for each of these metrics.\n",
    "    confi_auc = compute_bootstrap_confi(all_y_prob, all_y_test, roc_auc_score)\n",
    "    confi_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, accuracy_score)\n",
    "    confi_balanced_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, balanced_accuracy_score)\n",
    "    confi_precision = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_recall = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: recall_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_f1 = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: f1_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_auprc = compute_bootstrap_confi(all_y_prob, all_y_test, lambda y_true, y_pred_probs: compute_auprc(y_true, y_pred_probs))\n",
    "    confi_specificity = compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: cm[0, 0] / (cm[0, 0] + cm[0, 1]))\n",
    "    confi_ppv = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_npv = compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: (confusion_matrix(y_true, y_pred)[1,1] / (confusion_matrix(y_true, y_pred)[1,1] + confusion_matrix(y_true, y_pred)[0,1])))\n",
    "    \n",
    "    plot_roc_curve(all_y_test, all_y_prob, method, task)\n",
    "    plot_confusion_matrix(all_y_test, all_predictions, positive, negative, method, task)\n",
    "    \n",
    "    # Directory path\n",
    "    directory = \"./result\"\n",
    "    \n",
    "    # Construct the task specific directory path\n",
    "    task_directory = os.path.join(directory, task)\n",
    "    \n",
    "    # Ensure the task specific directory exists\n",
    "    os.makedirs(task_directory, exist_ok=True)\n",
    "    \n",
    "    # Construct complete file path for pickle file with 'results' + task + method as the filename\n",
    "    filename = f\"results_{task}_{method}.pickle\"\n",
    "    file_path = os.path.join(task_directory, filename)\n",
    "    \n",
    "    # Save the pickle file in the constructed path\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump((performance_dict, all_y_test, all_y_prob, all_predictions), f)\n",
    "\n",
    "        \n",
    "    print(f\"AUC: {auc} (95% CI: {confi_auc})\")\n",
    "    print(f\"Accuracy: {accuracy} (95% CI: {confi_accuracy})\")\n",
    "    print(f\"Balanced accuracy: {balanced_accuracy} (95% CI: {confi_balanced_accuracy})\")\n",
    "    print(f\"Precision per class: {precision_classwise[0]} {negative} (95% CI: {confi_precision[0]}), {precision_classwise[1]} {positive} (95% CI: {confi_precision[1]})\")\n",
    "    print(f\"Recall per class: {recall_classwise[0]} {negative} (95% CI: {confi_recall[0]}), {recall_classwise[1]} {positive} (95% CI: {confi_recall[1]})\")\n",
    "    print(f\"F1-score per class: {f1_classwise[0]} {negative} (95% CI: {confi_f1[0]}), {f1_classwise[1]} {positive} (95% CI: {confi_f1[1]})\")\n",
    "    print(f\"AUPRC: {auprc} (95% CI: {confi_auprc})\")\n",
    "    print(f\"Specificity: {specificity} (95% CI: {confi_specificity})\")\n",
    "    print(f\"PPV per class: {ppv[0]} {negative} (95% CI: {confi_ppv[0]}), {ppv[1]} {positive} (95% CI: {confi_ppv[1]})\")\n",
    "    print(f\"NPV: {npv} (95% CI: {confi_npv})\")\n",
    "    \n",
    "    \n",
    "    return performance_dict, all_y_test, all_y_prob, all_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nested_crossvalidation_late_fusion(data_pet, data_mri, label, method, task):\n",
    "    train_label = label\n",
    "    random_states = [10]\n",
    "    \n",
    "    performance_dict = {}\n",
    "    tasks_dict = {\n",
    "        'cd': ('AD', 'CN'),\n",
    "        'dm': ('AD', 'MCI'),\n",
    "        'cm': ('MCI', 'CN'),\n",
    "        'pc': ('Preclinical', 'CN')\n",
    "    }\n",
    "    \n",
    "    all_y_test = []\n",
    "    all_y_prob = []\n",
    "    all_predictions = []\n",
    "    performance_dict = {}\n",
    "    best_models_pet = []\n",
    "    best_models_mri = []\n",
    "    best_weights_list = []\n",
    "    best_auc_list = []\n",
    "    \n",
    "    positive, negative = tasks_dict[task]\n",
    "    train_data_pet = np.array(data_pet)\n",
    "    train_data_mri = np.array(data_mri)\n",
    "    train_label = np.array(train_label)\n",
    "    \n",
    "    for rs in random_states:\n",
    "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)        \n",
    "        for train_ix, test_ix in cv_outer.split(train_data_pet, train_label):\n",
    "            X_train_pet, X_test_pet = train_data_pet[train_ix, :], train_data_pet[test_ix, :]\n",
    "            X_train_mri, X_test_mri = train_data_mri[train_ix, :], train_data_mri[test_ix, :]\n",
    "            y_train, y_test = train_label[train_ix], train_label[test_ix]\n",
    "        \n",
    "            # Normalize the PET and MRI training data based on control indices within this fold\n",
    "            control_indices_train = [i for i, label in enumerate(y_train) if label == 0]\n",
    "            \n",
    "            # Calculate normalization parameters from the training data\n",
    "            X_train_pet, normalization_params_pet = normalize_features(X_train_pet, control_indices_train, return_params=True)\n",
    "            X_train_mri, normalization_params_mri = normalize_features(X_train_mri, control_indices_train, return_params=True)\n",
    "            \n",
    "            # Use those normalization parameters to normalize the test data\n",
    "            X_test_pet = apply_normalization(X_test_pet, normalization_params_pet)\n",
    "            X_test_mri = apply_normalization(X_test_mri, normalization_params_mri)\n",
    "        \n",
    "            # Compute kernel matrices for PET and MRI data\n",
    "            K_train_pet = compute_kernel_matrix(X_train_pet, X_train_pet, linear_kernel)\n",
    "            K_test_pet = compute_kernel_matrix(X_test_pet, X_train_pet, linear_kernel)\n",
    "            \n",
    "            K_train_mri = compute_kernel_matrix(X_train_mri, X_train_mri, linear_kernel)\n",
    "            K_test_mri = compute_kernel_matrix(X_test_mri, X_train_mri, linear_kernel)\n",
    "\n",
    "            best_auc = 0\n",
    "            best_weights = (0, 0)\n",
    "            \n",
    "            for w1 in np.linspace(0, 1, 51):  # 51 points for weights\n",
    "                w2 = 1 - w1\n",
    "                \n",
    "                cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "                \n",
    "                model_pet = SVC(kernel=\"precomputed\", class_weight='balanced', probability=True)\n",
    "                model_mri = SVC(kernel=\"precomputed\", class_weight='balanced', probability=True)\n",
    "                \n",
    "                space = {'C': [1, 100, 10, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    "                \n",
    "                search_pet = GridSearchCV(model_pet, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "                search_mri = GridSearchCV(model_mri, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "                \n",
    "                search_pet.fit(K_train_pet, y_train)\n",
    "                search_mri.fit(K_train_mri, y_train)\n",
    "                \n",
    "                pet_best = search_pet.best_estimator_\n",
    "                mri_best = search_mri.best_estimator_\n",
    "                \n",
    "                pet_prob = pet_best.predict_proba(K_test_pet)[:, 1]\n",
    "                mri_prob = mri_best.predict_proba(K_test_mri)[:, 1]\n",
    "                \n",
    "                fused_prob = w1 * pet_prob + w2 * mri_prob\n",
    "                \n",
    "                auc = roc_auc_score(y_test, fused_prob)\n",
    "                \n",
    "                if auc > best_auc:\n",
    "                    best_auc = auc\n",
    "                    best_weights = (w1, w2)\n",
    "                    best_w1=w1\n",
    "                    best_w2=w2\n",
    "            print(f\"Best weights for this fold: {best_weights}, AUC: {best_auc}\")\n",
    "            \n",
    "            search_pet.fit(K_train_pet, y_train)\n",
    "            search_mri.fit(K_train_mri, y_train)\n",
    "\n",
    "            pet_best = search_pet.best_estimator_\n",
    "            mri_best = search_mri.best_estimator_\n",
    "\n",
    "            pet_prob = pet_best.predict_proba(K_test_pet)[:, 1]\n",
    "            mri_prob = mri_best.predict_proba(K_test_mri)[:, 1]\n",
    "            fused_prob = best_w1 * pet_prob + best_w2 * mri_prob\n",
    "            yhat = fused_prob\n",
    "            y_test = np.array(train_label)[test_ix]\n",
    "            predictions = (yhat >= 0.5).astype(int)\n",
    "            all_y_test.extend(y_test.tolist())\n",
    "            all_y_prob.extend(yhat.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            \n",
    "            for params, mean_score, std_score in zip(search_pet.cv_results_['params'], \n",
    "                                                     search_pet.cv_results_['mean_test_score'], \n",
    "                                                     search_pet.cv_results_['std_test_score']):\n",
    "                C_value = params['C']\n",
    "                if C_value not in performance_dict:\n",
    "                    performance_dict[C_value] = {'mean_scores': [], 'std_scores': []}\n",
    "                performance_dict[C_value]['mean_scores'].append(mean_score)\n",
    "                performance_dict[C_value]['std_scores'].append(std_score)\n",
    "\n",
    "    auc = roc_auc_score(all_y_test, all_y_prob)\n",
    "    accuracy = accuracy_score(all_y_test, all_predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle UndefinedMetricWarning by setting zero_division=1\n",
    "    precision_classwise = precision_score(all_y_test, all_predictions, average=None, zero_division=1)\n",
    "    recall_classwise = recall_score(all_y_test, all_predictions, average=None)\n",
    "    f1_classwise = f1_score(all_y_test, all_predictions, average=None)\n",
    "    \n",
    "    ppv = precision_classwise  # since they are the same, no need to compute twice\n",
    "    \n",
    "    cm = confusion_matrix(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle RuntimeWarning by checking for zero denominator\n",
    "    denominator = cm[1,1] + cm[0,1]\n",
    "    npv = cm[1,1] / denominator if denominator != 0 else 0\n",
    "\n",
    "    \n",
    "    # 2. Compute bootstrap confidence intervals for each of these metrics.\n",
    "    confi_auc = compute_bootstrap_confi(all_y_prob, all_y_test, roc_auc_score)\n",
    "    confi_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, accuracy_score)\n",
    "    confi_balanced_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, balanced_accuracy_score)\n",
    "    confi_precision = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_recall = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: recall_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_f1 = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: f1_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_ppv = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_npv = compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: (confusion_matrix(y_true, y_pred)[1,1] / (confusion_matrix(y_true, y_pred)[1,1] + confusion_matrix(y_true, y_pred)[0,1])))\n",
    "    \n",
    "    plot_roc_curve(all_y_test, all_y_prob, method, task)\n",
    "    plot_confusion_matrix(all_y_test, all_predictions, positive, negative, method, task)\n",
    "    \n",
    "    directory = './result'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    filename = os.path.join(directory, f'results_{method}_{task}.pickle')\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((performance_dict, all_y_test, all_y_prob, all_predictions), f)\n",
    "        \n",
    "    print(f\"AUC: {auc} (95% CI: {confi_auc})\")\n",
    "    print(f\"Accuracy: {accuracy} (95% CI: {confi_accuracy})\")\n",
    "    print(f\"Balanced accuracy: {balanced_accuracy} (95% CI: {confi_balanced_accuracy})\")\n",
    "    print(f\"Precision per class: {precision_classwise[0]} {negative} (95% CI: {confi_precision[0]}), {precision_classwise[1]} {positive} (95% CI: {confi_precision[1]})\")\n",
    "    print(f\"Recall per class: {recall_classwise[0]} {negative} (95% CI: {confi_recall[0]}), {recall_classwise[1]} {positive} (95% CI: {confi_recall[1]})\")\n",
    "    print(f\"F1-score per class: {f1_classwise[0]} {negative} (95% CI: {confi_f1[0]}), {f1_classwise[1]} {positive} (95% CI: {confi_f1[1]})\")\n",
    "    print(f\"PPV per class: {ppv[0]} {negative} (95% CI: {confi_ppv[0]}), {ppv[1]} {positive} (95% CI: {confi_ppv[1]})\")\n",
    "    print(f\"NPV: {npv} (95% CI: {confi_npv})\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_kernel(K):\n",
    "    diag_elements = np.diag(K)\n",
    "    if np.any(diag_elements == 0):\n",
    "        raise ValueError(\"Zero diagonal element found in kernel matrix\")\n",
    "    K_normalized = K / np.sqrt(np.outer(diag_elements, diag_elements))\n",
    "    return K_normalized\n",
    "\n",
    "def normalize_test_kernel(K_test, K_train_diag, K_test_diag):\n",
    "    # Check for zeros to prevent division by zero errors\n",
    "    if np.any(K_train_diag == 0) or np.any(K_test_diag == 0):\n",
    "        raise ValueError(\"Zero diagonal element found in kernel matrix\")\n",
    "    \n",
    "    # Compute the normalization factors: should result in a matrix of shape (len(K_train_diag), len(K_test_diag))\n",
    "    normalization_matrix = np.sqrt(np.outer(K_train_diag, K_test_diag))\n",
    "    \n",
    "    # Correctly reshape the normalization matrix to match K_test dimensions\n",
    "    # This involves transposing the matrix since np.outer produces (train, test) and we need (test, train)\n",
    "    normalization_matrix = normalization_matrix.T\n",
    "    \n",
    "    # Perform element-wise division\n",
    "    K_test_normalized = K_test / normalization_matrix\n",
    "    return K_test_normalized\n",
    "\n",
    "\n",
    "\n",
    "def nested_crossvalidation_multi_kernel(data_pet, data_mri, label, method, task):\n",
    "    train_label = label\n",
    "    random_states = [10]\n",
    "    \n",
    "    performance_dict = {}\n",
    "    tasks_dict = {\n",
    "        'cd': ('AD', 'CN'),\n",
    "        'dm': ('AD', 'MCI'),\n",
    "        'cm': ('MCI', 'CN'),\n",
    "        'pc': ('Preclinical', 'CN')\n",
    "    }\n",
    "    \n",
    "    all_y_test = []\n",
    "    all_y_prob = []\n",
    "    all_predictions = []\n",
    "    performance_dict = {}\n",
    "    best_models_pet = []\n",
    "    best_models_mri = []\n",
    "    best_weights_list = []\n",
    "    best_auc_list = []\n",
    "    \n",
    "    positive, negative = tasks_dict[task]\n",
    "    train_data_pet = np.array(data_pet)\n",
    "    train_data_mri = np.array(data_mri)\n",
    "    train_label = np.array(train_label)\n",
    "    \n",
    "    for rs in random_states:\n",
    "        cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)        \n",
    "        for train_ix, test_ix in cv_outer.split(train_data_pet, train_label):\n",
    "            X_train_pet, X_test_pet = train_data_pet[train_ix, :], train_data_pet[test_ix, :]\n",
    "            X_train_mri, X_test_mri = train_data_mri[train_ix, :], train_data_mri[test_ix, :]\n",
    "            y_train, y_test = train_label[train_ix], train_label[test_ix]\n",
    "        \n",
    "            # Normalize the PET and MRI training data based on control indices within this fold\n",
    "            control_indices_train = [i for i, label in enumerate(y_train) if label == 0]\n",
    "            \n",
    "            # Calculate normalization parameters from the training data\n",
    "            X_train_pet, normalization_params_pet = normalize_features(X_train_pet, control_indices_train, return_params=True)\n",
    "            X_train_mri, normalization_params_mri = normalize_features(X_train_mri, control_indices_train, return_params=True)\n",
    "            \n",
    "            # Use those normalization parameters to normalize the test data\n",
    "            X_test_pet = apply_normalization(X_test_pet, normalization_params_pet)\n",
    "            X_test_mri = apply_normalization(X_test_mri, normalization_params_mri)\n",
    "        \n",
    "            # Compute kernel matrices for PET and MRI data\n",
    "            K_train_pet = compute_kernel_matrix(X_train_pet, X_train_pet, linear_kernel)\n",
    "            K_test_pet = compute_kernel_matrix(X_test_pet, X_train_pet, linear_kernel)\n",
    "            \n",
    "            K_train_mri = compute_kernel_matrix(X_train_mri, X_train_mri, linear_kernel)\n",
    "            K_test_mri = compute_kernel_matrix(X_test_mri, X_train_mri, linear_kernel)\n",
    "\n",
    "            # Extract diagonals before normalizing\n",
    "            K_train_mri_diag = np.diag(K_train_mri)\n",
    "            K_train_pet_diag = np.diag(K_train_pet)\n",
    "            K_test_mri_diag = np.diag(K_test_mri)\n",
    "            K_test_pet_diag = np.diag(K_test_pet)\n",
    "            \n",
    "            # Normalize training kernels\n",
    "            K_train_mri = normalize_kernel(K_train_mri)\n",
    "            K_train_pet = normalize_kernel(K_train_pet)\n",
    "            \n",
    "            \n",
    "            # Normalize test kernels using the original (unnormalized) training kernel diagonals\n",
    "            K_test_mri = normalize_test_kernel(K_test_mri, K_train_mri_diag, K_test_mri_diag)\n",
    "            K_test_pet = normalize_test_kernel(K_test_pet, K_train_pet_diag, K_test_pet_diag)\n",
    "\n",
    "            # Check for NaN values after normalization\n",
    "            if np.isnan(K_train_pet).any() or np.isnan(K_test_pet).any() or np.isnan(K_train_mri).any() or np.isnan(K_test_mri).any():\n",
    "                raise ValueError(\"NaN values found in kernel matrices after normalization\")\n",
    "\n",
    "            best_auc = 0\n",
    "            best_weights = (0, 0)\n",
    "            \n",
    "            for w1 in np.linspace(0, 1, 51):  # 51 points for weights\n",
    "                w2 = 1 - w1\n",
    "                \n",
    "                # Combine kernels using weighted sum\n",
    "                K_train_combined = w1 * K_train_pet + w2 * K_train_mri\n",
    "                K_test_combined = w1 * K_test_pet + w2 * K_test_mri\n",
    "                \n",
    "                cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "                \n",
    "                model = SVC(kernel=\"precomputed\", class_weight='balanced', probability=True)\n",
    "                \n",
    "                space = {'C': [1, 100, 10, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    "                \n",
    "                search = GridSearchCV(model, space, scoring='roc_auc', cv=cv_inner, refit=True)\n",
    "                \n",
    "                search.fit(K_train_combined, y_train)\n",
    "                \n",
    "                best_model = search.best_estimator_\n",
    "                \n",
    "                # Predict probabilities on the test set\n",
    "                test_prob = best_model.predict_proba(K_test_combined)[:, 1]\n",
    "                \n",
    "                # Calculate AUC\n",
    "                auc = roc_auc_score(y_test, test_prob)\n",
    "                \n",
    "                # Track the best AUC and corresponding weights\n",
    "                if auc > best_auc:\n",
    "                    best_auc = auc\n",
    "                    best_weights = (w1, w2)\n",
    "                    best_w1 = w1\n",
    "                    best_w2 = w2\n",
    "            \n",
    "            print(f\"Best weights for this fold: {best_weights}, AUC: {best_auc}\")\n",
    "            \n",
    "            # Re-train the best model with the best weights\n",
    "            K_train_combined = best_w1 * K_train_pet + best_w2 * K_train_mri\n",
    "            K_test_combined = best_w1 * K_test_pet + best_w2 * K_test_mri\n",
    "\n",
    "            search.fit(K_train_combined, y_train)\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            # Predict probabilities on the test set\n",
    "            yhat = best_model.predict_proba(K_test_combined)[:, 1]\n",
    "            predictions = (yhat >= 0.5).astype(int)\n",
    "\n",
    "            all_y_test.extend(y_test.tolist())\n",
    "            all_y_prob.extend(yhat.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "            \n",
    "            for params, mean_score, std_score in zip(search.cv_results_['params'], \n",
    "                                                     search.cv_results_['mean_test_score'], \n",
    "                                                     search.cv_results_['std_test_score']):\n",
    "                C_value = params['C']\n",
    "                if C_value not in performance_dict:\n",
    "                    performance_dict[C_value] = {'mean_scores': [], 'std_scores': []}\n",
    "                performance_dict[C_value]['mean_scores'].append(mean_score)\n",
    "                performance_dict[C_value]['std_scores'].append(std_score)\n",
    "\n",
    "    auc = roc_auc_score(all_y_test, all_y_prob)\n",
    "    accuracy = accuracy_score(all_y_test, all_predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle UndefinedMetricWarning by setting zero_division=1\n",
    "    precision_classwise = precision_score(all_y_test, all_predictions, average=None, zero_division=1)\n",
    "    recall_classwise = recall_score(all_y_test, all_predictions, average=None)\n",
    "    f1_classwise = f1_score(all_y_test, all_predictions, average=None)\n",
    "    \n",
    "    ppv = precision_classwise  # since they are the same, no need to compute twice\n",
    "    \n",
    "    cm = confusion_matrix(all_y_test, all_predictions)\n",
    "    \n",
    "    # Handle RuntimeWarning by checking for zero denominator\n",
    "    denominator = cm[1,1] + cm[0,1]\n",
    "    npv = cm[1,1] / denominator if denominator != 0 else 0\n",
    "\n",
    "    \n",
    "    # Compute bootstrap confidence intervals for each of these metrics\n",
    "    confi_auc = compute_bootstrap_confi(all_y_prob, all_y_test, roc_auc_score)\n",
    "    confi_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, accuracy_score)\n",
    "    confi_balanced_accuracy = compute_bootstrap_confi(all_predictions, all_y_test, balanced_accuracy_score)\n",
    "    confi_precision = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_recall = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: recall_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_f1 = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: f1_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_ppv = [compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: precision_score(y_true, y_pred, average=None)[i]) for i in range(2)]\n",
    "    confi_npv = compute_bootstrap_confi(all_predictions, all_y_test, lambda y_true, y_pred: (confusion_matrix(y_true, y_pred)[1,1] / (confusion_matrix(y_true, y_pred)[1,1] + confusion_matrix(y_true, y_pred)[0,1])))\n",
    "    \n",
    "    plot_roc_curve(all_y_test, all_y_prob, method, task)\n",
    "    plot_confusion_matrix(all_y_test, all_predictions, positive, negative, method, task)\n",
    "    \n",
    "    directory = './result'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    filename = os.path.join(directory, f'results_{method}_{task}.pickle')\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((performance_dict, all_y_test, all_y_prob, all_predictions), f)\n",
    "        \n",
    "    print(f\"AUC: {auc} (95% CI: {confi_auc})\")\n",
    "    print(f\"Accuracy: {accuracy} (95% CI: {confi_accuracy})\")\n",
    "    print(f\"Balanced accuracy: {balanced_accuracy} (95% CI: {confi_balanced_accuracy})\")\n",
    "    print(f\"Precision per class: {precision_classwise[0]} {negative} (95% CI: {confi_precision[0]}), {precision_classwise[1]} {positive} (95% CI: {confi_precision[1]})\")\n",
    "    print(f\"Recall per class: {recall_classwise[0]} {negative} (95% CI: {confi_recall[0]}), {recall_classwise[1]} {positive} (95% CI: {confi_recall[1]})\")\n",
    "    print(f\"F1-score per class: {f1_classwise[0]} {negative} (95% CI: {confi_f1[0]}), {f1_classwise[1]} {positive} (95% CI: {confi_f1[1]})\")\n",
    "    print(f\"PPV per class: {ppv[0]} {negative} (95% CI: {confi_ppv[0]}), {ppv[1]} {positive} (95% CI: {confi_ppv[1]})\")\n",
    "    print(f\"NPV: {npv} (95% CI: {confi_npv})\")\n",
    "\n",
    "    return performance_dict, all_y_test, all_y_prob, all_predictions\n",
    "\n",
    "# The normalize_features, apply_normalization, compute_kernel_matrix, linear_kernel, compute_bootstrap_confi, plot_roc_curve, and plot_confusion_matrix functions are assumed to be defined elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a96630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b581f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "import glob\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy.ndimage as ndi\n",
    "import statsmodels.stats.contingency_tables as ct\n",
    "import time\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nilearn import image, plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.masking import (apply_mask, compute_brain_mask,\n",
    "                             compute_multi_brain_mask, intersect_masks, unmask)\n",
    "from nilearn.plotting import plot_roi, plot_stat_map, show\n",
    "from numpy import mean, std\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import chi2_contingency, norm\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix,\n",
    "                             precision_recall_curve, precision_recall_fscore_support,\n",
    "                             roc_auc_score, roc_curve)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, StratifiedKFold,\n",
    "                                     cross_val_predict, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import Binarizer, label_binarize\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate(images,labels,task):\n",
    "    imagesData=[]\n",
    "    labelsData=[]\n",
    "    cn=0\n",
    "    pcn=0\n",
    "    dementia=0\n",
    "    mci=0\n",
    "    for i in range(len(images)):\n",
    "      if labels[i]=='CN':\n",
    "        cn+=1\n",
    "      if labels[i]=='MCI':\n",
    "        mci+=1\n",
    "      if labels[i]=='Dementia':\n",
    "        dementia+=1\n",
    "      if labels[i]=='PCN':\n",
    "        pcn+=1\n",
    "    print(\"Number of CN subjects:\")\n",
    "    print(cn)\n",
    "    print(\"Number of PCN subjects:\")\n",
    "    print(pcn)\n",
    "    print(\"Number of MCI subjects:\")\n",
    "    print(mci)\n",
    "    print(\"Number of Dementia subjects:\")\n",
    "    print(dementia)\n",
    "    if task == \"cd\":\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == \"CN\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "            if labels[i] == \"Dementia\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "    if task == \"cm\":\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == \"CN\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "            if labels[i] == \"MCI\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "    if task == \"dm\":\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == \"Dementia\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "            if labels[i] == \"MCI\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "    if task == \"pc\":\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == \"PCN\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "            if labels[i] == \"CN\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])   \n",
    "    if task == 'cdm':\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == \"CN\":\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "            if labels[i] == \"Dementia\" or labels[i] == 'MCI':\n",
    "                imagesData.append(images[i])\n",
    "                labelsData.append(labels[i])\n",
    "    print(\"lenth of dataset: \")\n",
    "    print(len(labelsData))\n",
    "      \n",
    "        \n",
    "    return imagesData,labelsData\n",
    "\n",
    "\n",
    "def generate_data_path():\n",
    "    files=['/scratch/jjlee/Singularity/ADNI/bids/derivatives/table_preclinical_cross-sectional.csv','/scratch/jjlee/Singularity/ADNI/bids/derivatives/table_cn_cross-sectional.csv','/scratch/jjlee/Singularity/ADNI/bids/derivatives/table_cdr_0p5_apos_cross-sectional.csv','/scratch/jjlee/Singularity/ADNI/bids/derivatives/table_cdr_gt_0p5_apos_cross-sectional.csv']\n",
    "    class_labels=['PCN','CN','MCI','Dementia']\n",
    "    pet_paths = []\n",
    "    mri_paths = []\n",
    "    class_labels_out = []\n",
    "\n",
    "    for file, class_label in zip(files, class_labels):\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract sub-xxxx and ses-xxxx from original paths\n",
    "            sub_ses_info = \"/\".join(row['FdgFilename'].split(\"/\")[8:10])\n",
    "\n",
    "            # Generate new directory\n",
    "            new_directory = os.path.join('/scratch/l.peiwang/derivatives_new', sub_ses_info, 'pet')\n",
    "\n",
    "            # Get all files that match the pattern but then exclude ones that contain 'icv'\n",
    "            pet_files = [f for f in glob.glob(new_directory + '/*FDG*') if 'icv' not in f]\n",
    "            mri_files = glob.glob(new_directory + '/*detJ*icv*')\n",
    "            if pet_files and mri_files:  # If both lists are not empty\n",
    "                pet_paths.append(pet_files[0])  # Append the first PET file found\n",
    "                mri_paths.append(mri_files[0])  # Append the first MRI file found\n",
    "                class_labels_out.append(class_label)  # Associate class label with the path\n",
    "\n",
    "    return pet_paths, mri_paths, class_labels_out\n",
    "\n",
    "\n",
    "def binarylabel(train_label,mode):\n",
    "    if mode==\"cd\" or mode==\"cdm\":\n",
    "        for i in range(len(train_label)):\n",
    "            if train_label[i]==\"CN\":\n",
    "                train_label[i]=0\n",
    "            else:\n",
    "                train_label[i]=1\n",
    "    if mode==\"cm\":\n",
    "        for i in range(len(train_label)):\n",
    "            if train_label[i]==\"CN\":\n",
    "                train_label[i]=0\n",
    "            else:\n",
    "                train_label[i]=1\n",
    "    if mode==\"dm\":\n",
    "        for i in range(len(train_label)):\n",
    "            if train_label[i]==\"Dementia\":\n",
    "                train_label[i]=1\n",
    "            else:\n",
    "                train_label[i]=0\n",
    "    if mode==\"pc\":\n",
    "        for i in range(len(train_label)):\n",
    "            if train_label[i]==\"CN\":\n",
    "                train_label[i]=0\n",
    "            else:\n",
    "                train_label[i]=1\n",
    "    if mode==\"pm\":\n",
    "        for i in range(len(train_label)):\n",
    "            if train_label[i]==\"EMCI\":\n",
    "                train_label[i]=1\n",
    "            else:\n",
    "                train_label[i]=0\n",
    "    return train_label\n",
    "\n",
    "\n",
    "\n",
    "def loading_mask(task,modality):\n",
    "    #Loading and generating data\n",
    "    images_pet,images_mri,labels=generate_data_path()\n",
    "    if modality == 'PET':\n",
    "        data_train,train_label=generate(images_pet,labels,task)\n",
    "    if modality == 'MRI':\n",
    "        data_train,train_label=generate(images_mri,labels,task)\n",
    "    masker = NiftiMasker(mask_img='/home/l.peiwang/MR-PET-Classfication/mask_gm_p4_new4.nii')\n",
    "    train_data=[]\n",
    "    for i in range(len(data_train)):\n",
    "        a=masker.fit_transform(data_train[i])\n",
    "        train_data.append(a)\n",
    "\n",
    "    train_label=binarylabel(train_label,task)\n",
    "    train_data=np.array(train_data).reshape(np.array(train_label).shape[0],122597)\n",
    "    \n",
    "    return train_data,train_label,masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29febd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b14b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CN subjects:\n",
      "263\n",
      "Number of PCN subjects:\n",
      "140\n",
      "Number of MCI subjects:\n",
      "458\n",
      "Number of Dementia subjects:\n",
      "151\n",
      "lenth of dataset: \n",
      "721\n",
      "Number of CN subjects:\n",
      "263\n",
      "Number of PCN subjects:\n",
      "140\n",
      "Number of MCI subjects:\n",
      "458\n",
      "Number of Dementia subjects:\n",
      "151\n",
      "lenth of dataset: \n",
      "721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/export/anaconda/anaconda3/anaconda3-2022.05/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:110: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_mri1,label,masker=loading_mask('cm','MRI')\n",
    "image_pet1,label,masker=loading_mask('cm','PET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533195fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X, indices, return_params=False):\n",
    "    scaler = MinMaxScaler()\n",
    "    print(\"j\")\n",
    "    scaler.fit(X[indices])  # Fit only to control group data\n",
    "    X_scaled = scaler.transform(X)  # Apply to all data\n",
    "    if return_params:\n",
    "        return X_scaled, scaler\n",
    "    return X_scaled\n",
    "\n",
    "def apply_normalization(X, scaler):\n",
    "    return scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90435ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "# test_size specifies the proportion of the test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(image_pet1, label, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d61651ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_indices_train = [i for i, label in enumerate(Y_train) if label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5475dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n"
     ]
    }
   ],
   "source": [
    "X_train_pet, normalization_params_pet = normalize_features(X_train, control_indices_train, return_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4167f30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 122597)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0729d5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 122597)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd981825",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pet = apply_normalization(X_test, normalization_params_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a3fd36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 122597)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9db47737",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_train_pet = compute_kernel_matrix(X_train_pet, X_train_pet, linear_kernel)\n",
    "K_test_pet = compute_kernel_matrix(X_test_pet, X_train_pet, linear_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18e9bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 576)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c724939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 576)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_test_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed6f9447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66382.9809467 ,   6327.79406362,  46415.5810965 ,  67434.98474955,\n",
       "        73834.81065024,  66013.49639953,   6043.85081107,  68385.53632476,\n",
       "        56538.84762228,  57405.71493545,  51636.16628371,  56354.62791135,\n",
       "        65213.52310964,  67262.27869196,  61321.84687185,  52722.90697268,\n",
       "        50891.55540839,  80621.84322441,   7223.31907746,  49008.30196295,\n",
       "        50881.98980195,  59314.12039093,  62476.47966664,  71995.32040548,\n",
       "        66196.97294709,  74386.24719215,  52250.47002348,  55158.20690028,\n",
       "         6999.89251332,  46103.61757934,  51268.78445892,  64586.66233743,\n",
       "        52445.31037358,  66375.96018904,  49557.302979  ,   5993.42226687,\n",
       "        47275.18315679,  54863.78834937,  54529.68723985,  82416.78977328,\n",
       "        51946.98268178,  63507.02934258,  61354.13343994,  70872.79052563,\n",
       "        66015.82586232,   6228.93357975,  59039.29784488,  66279.93872322,\n",
       "        43072.11115294,  55947.28516956,   4643.07788933,  81836.56194819,\n",
       "         8078.39170076,  50166.03624617,  61510.87442504,  47834.33915986,\n",
       "        51472.29260513,  54265.89305487,  53816.49767147,  43375.83744168,\n",
       "        54782.08673466,  56500.1465363 ,  73117.877736  ,  52351.77499995,\n",
       "        73110.5082528 ,  45994.39234475,  66466.69371801,  54119.22988575,\n",
       "        50792.27797244,  48456.97096064,  60222.08569848,  78605.43191095,\n",
       "        54634.1057078 ,  72274.9697004 ,  56841.93481892,  50198.9790188 ,\n",
       "        43260.04533149,  55392.92301597,  52814.69178943,  47156.49783242,\n",
       "        50931.23383651,  40526.39036507,  37019.28430146,  47961.37618427,\n",
       "        61340.01646547,  51913.62154228,  65609.74897928,  51434.44301709,\n",
       "        74174.00733489,  52476.90449964,  63110.20358691,  56598.85129599,\n",
       "        47679.37903   ,  63816.74395305,  46229.27586607,  50616.35883281,\n",
       "        62787.0537608 ,  38619.755782  ,  49989.70940603,   6062.06882461,\n",
       "        52425.64281716,  70779.6482584 ,  47506.42339269,  95564.06390361,\n",
       "        56987.39581313,  65081.4907815 ,  46077.96971253,  59808.02185083,\n",
       "        10554.98768366,  86497.32532504,  52682.60541237,  56604.29336589,\n",
       "        45703.8015437 ,  63272.4224851 ,  55780.20282388,   6836.70656563,\n",
       "        56512.06036445,  56215.0668987 ,  57738.76075903,  58740.59113402,\n",
       "        65476.88845007,  54442.29663538,  63980.08740794,  71175.59481247,\n",
       "         6298.05905211,  52040.4298518 ,  51860.69524907,  53423.55242996,\n",
       "        48672.90555141,  58193.58433833,  65987.23943616,  65955.51186095,\n",
       "        52121.40371968,  62730.32597688,  59094.11687117,   5001.3670039 ,\n",
       "        75556.86403541,  54921.80816759,  50077.41944204,  44895.98010488,\n",
       "        55959.88476619,  75731.89249395,   5164.72317703,   5148.56152836,\n",
       "         6594.0004414 ,  50245.14653818,  64024.78493111,  70702.51617425,\n",
       "        57946.23988677,  73953.49139112,  57385.81638577,  75800.41590809,\n",
       "        60901.52186716,  54307.12682203,  46867.97614726,  73732.18368708,\n",
       "        78123.85331306,  43700.07208979,  62802.94436406,  45488.76455327,\n",
       "        52099.69706672,  49884.28751191,  51150.46090576,  56401.00580907,\n",
       "        57916.07055444,  53218.28758822,  54152.1981058 ,  47143.29105204,\n",
       "        65054.93750433,  63569.01909215,  71660.87930568,   8851.99422207,\n",
       "        46595.43761973,  47424.73066548,  61810.85871467,  49418.35691942,\n",
       "        55734.19025589,  47711.03732591,  64816.43162798,  58151.3099084 ,\n",
       "        34194.16768579,  62683.49661966,  71875.63477086,  53989.59970003,\n",
       "        52608.90386722,  48407.64124385,  75859.5055429 ,  44551.9640717 ,\n",
       "        66677.37610193,  58707.06687851,  46819.27779926,  58439.01002074,\n",
       "        45557.68613922,   6206.4348852 ,  49245.99456744,  84225.88645532,\n",
       "        53836.40690159,  44602.49946858, 105663.3544803 ,  40755.02127456,\n",
       "        54046.10588441,  60333.09719695,  62888.59861758,  70985.1859466 ,\n",
       "        64522.23367381,  45280.3124983 ,  57146.61878675,  62409.40406864,\n",
       "        69088.62023376,  62633.83596146,  42933.246434  ,  54211.77410872,\n",
       "        54280.31212864,  65128.35228483,  57831.5170688 ,  52282.85930909,\n",
       "        51031.99447172,  17319.11109861,  55166.78500472,  66347.10729173,\n",
       "        54066.23100352,  71500.19099468,  59305.5952296 ,  62262.1013954 ,\n",
       "        53290.82857499,   6810.04526748,  44527.5298324 ,  52677.71422639,\n",
       "        61996.67656161,  71065.60344102,  79828.20416735,  66357.74124281,\n",
       "        51902.97663946,  66539.95221423,  51173.92964761,  76006.45107993,\n",
       "        10618.75235747,   6306.70559216,  66904.93187407,  58058.18122743,\n",
       "        59738.02930189,  10453.99953296,  78200.51215867,  54109.86805054,\n",
       "        49412.58478924,   6736.79910258,  57112.09240588,  10658.45921749,\n",
       "        54286.96006158,   7085.71743392,  62488.15159235,  62384.66021951,\n",
       "        46745.58890635,  63053.9419246 ,   9528.62750162,  63798.77543032,\n",
       "        50482.06151527,   8966.72326431,  43984.3820984 ,  62935.81547513,\n",
       "        45363.88594616,  58181.21484747,   6563.28373561,  64393.96536522,\n",
       "        51553.84731668,  58568.16729133,  61226.74954372,  58002.04787052,\n",
       "        71266.38667521,  67236.12412058,  58166.70590201,  57090.80667974,\n",
       "        50381.43158137,  39459.35093278,  57621.02451431,   5178.73449307,\n",
       "         7157.64165303,  52514.19017702,  10972.35825301,  83815.74248294,\n",
       "        52651.13828736,  66875.60105314,   8625.08871469,  68523.70260542,\n",
       "        66051.72059153,  69941.74516076,  46988.86970174,  60997.914496  ,\n",
       "        51160.08647082,  53944.28247278,  54724.77564319,  56843.39159509,\n",
       "        47885.61159098,  48941.93499283,  59224.04522795,  58389.64980464,\n",
       "        70533.63880976,  69811.80024655,  62030.01043256,  60304.66860765,\n",
       "        50336.82362477,  47006.71248679,  51550.08514806,  52110.57391814,\n",
       "        59823.55743197,  41653.17908632,   6254.31729786,  75654.43780002,\n",
       "        47135.14180431,   7065.94302925,  72263.62689108,  53627.00073166,\n",
       "        47914.36261417,  75102.39371252,  55800.75828248,  40492.4182657 ,\n",
       "        44926.6430421 ,  11258.00058703,  45544.87547578,  46705.33243086,\n",
       "        58625.85304476,  56822.96791339,  59036.79005837,  51865.2649762 ,\n",
       "        53196.03784424,  72947.99144588,  64326.91643869,  75864.81870926,\n",
       "        57999.3221121 ,  79228.98997781,  58892.33894601,  69073.89653051,\n",
       "         5776.6817591 ,  49269.81135788,  66625.37474269,  62091.21303834,\n",
       "        57797.01566745,  46264.99829201,  45389.66730641,  65614.3884956 ,\n",
       "        70199.15025271,  42008.52809132,  38676.97096754,  55592.12962982,\n",
       "        76540.68444291,  51523.61131694,  63075.15849509,   5752.23076534,\n",
       "        63022.63812772,  69830.35240192,   7254.82287977,  63259.18631368,\n",
       "        38542.28685178,  61924.79309662,  65511.6156956 ,  55879.88748649,\n",
       "        78362.62777838,  68210.77520878,  58172.02999799,  62236.48103364,\n",
       "        62424.42789923,  51759.80042321,  49998.7714728 ,  73049.39743363,\n",
       "        55097.66063806,  63542.96687535,  65994.22272882,  49288.92839116,\n",
       "        66818.65390719,  58887.32108948,  58353.30857787,  58545.22609821,\n",
       "        79761.23228543,  51628.96795768,  53180.2981989 ,   8254.23704646,\n",
       "        38157.48557543,  43213.54608929,  67353.31575485,  53701.10541686,\n",
       "        52480.03015551,  53897.79616489,  59849.03005626,  64158.87464227,\n",
       "        75466.12153665,  55848.37455351,  62454.46390621,  52637.89365545,\n",
       "        44980.9219293 ,  62695.86140017,  58987.38117352,  48291.17423477,\n",
       "        70715.38959202,  50817.43138449,  77885.30860144,  48888.85693646,\n",
       "        49952.43648173,  59907.46188555,  50323.42969459,   9835.62587117,\n",
       "        44686.56274723,  48142.91654384,  58333.59527338,  41967.30588027,\n",
       "        46887.67803808,   7987.66639956,  79937.65286225,  68743.98225102,\n",
       "        43250.02702397,  79040.7731321 ,  65245.49079936,  56465.48587559,\n",
       "         6838.3453679 ,  58217.44872694,  58036.27716689,  43862.96209446,\n",
       "        54603.81610526,  51475.60800402,   7553.14882889,   9820.9341769 ,\n",
       "         7768.62560598,  56821.6060573 ,  55855.66389291,  83609.91377382,\n",
       "        58343.8164393 ,  68169.35032037,   4426.96955011,  50078.96069454,\n",
       "        69687.26237192,   5845.89109314,  56120.641462  ,  47525.36473825,\n",
       "        68168.05709728,  48190.44389725,  69367.76631642, 101968.26590207,\n",
       "        68656.81324161,  60301.72089501,  60342.40710606,  38774.01039568,\n",
       "        51582.63355012,  46318.08144187,  56005.02838156,  60641.45643508,\n",
       "        53111.88731821,  47642.39184206,  50703.21794021,  58561.42180514,\n",
       "        56722.01311406,  82900.39119708,  50987.41457239,  66576.69712395,\n",
       "        52995.18578261,  50521.36737596,  61424.81173617,  52146.33871734,\n",
       "        52041.8825329 ,  85096.98031246,  57755.78327431,  55962.7142097 ,\n",
       "        48814.05491783,  65151.57455824,  41353.99640478,   7086.81094067,\n",
       "        52653.28219095,  68482.05783752,  62633.69023223,  45046.96379628,\n",
       "        59120.17299641,  54904.82778586,   6718.61576655,  49813.14066089,\n",
       "        57748.67920651,  59688.83812075,  51118.89778305,  61649.00552166,\n",
       "        51942.54772833,  81557.9161244 ,  39355.03889507,  50931.56669633,\n",
       "        43730.69788069,   5321.09457939,  54650.35125537,  65530.27205159,\n",
       "        70782.00513899,  58422.06599244,  60080.63795954,  71845.347595  ,\n",
       "        56051.03543014,  75775.89649104,  64082.55876532,  71252.3814758 ,\n",
       "        56879.51590944,  49299.36648173,  10861.7205576 ,  67649.06921098,\n",
       "        78802.86384998,  45666.69135557,   8813.95379521,   4245.78232936,\n",
       "        44601.11249244,  73296.25082593,  63245.5610093 ,  59294.08981338,\n",
       "        40955.76663281,  57010.98427325,  50694.38281661,  75644.63471821,\n",
       "        74168.28218558,  66024.15144156,  50420.82211403,  59473.69527282,\n",
       "        54563.6970473 ,  63510.71626521,  64458.90655497,   7310.64979677,\n",
       "        46926.581335  ,  70210.21043564,  66789.1706116 ,  52926.72496795,\n",
       "        47769.84344591,  52590.93175367,  50888.84075721,  57330.6357156 ,\n",
       "        60829.53941363,  44662.75707732,  51236.22234416,  55503.15023213,\n",
       "        55539.42589405,  64929.26788964,  56495.31966161,  55739.68074237,\n",
       "         8294.36770243,   8394.1163799 ,   9637.53541868,  68239.90618364,\n",
       "        47086.40729308,   8564.89739686,  65132.42430725,  58546.76721805,\n",
       "        47795.66079137,   6166.38776208,  61422.31166894,  62431.2834375 ,\n",
       "        67262.49434577,  55283.31251405,  64703.82564816,  39730.10411539,\n",
       "         6347.44212416,  55899.03075921,  80425.82549229,  69525.19909636,\n",
       "        48509.21486174,   5457.55998347,  66119.91908636,  51324.78008698,\n",
       "        62430.45346235,  70602.40396518,  62270.69374631,  60810.54932826,\n",
       "        55194.52591123,  39835.5913083 ,  65298.88952536,   6786.62588002,\n",
       "        56112.09878922,  48952.50307194,  51620.30600898,  57732.16013319,\n",
       "        57769.79033026,  57219.37098709,   9729.36693306,  61518.63190812,\n",
       "        41684.40962632,  47899.17865637,  65329.48342365,  49425.67903278])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(K_train_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04e9f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63521.33559726,  7071.60109983, 54360.10293977, 61366.92409935,\n",
       "       74140.10790418, 59306.25337863,  5290.02510391, 51301.69217078,\n",
       "       49504.67717353, 56460.91425016, 50511.42332857, 52482.68794083,\n",
       "       54614.05122267, 60620.31334211,  6709.31756492, 47986.76195141,\n",
       "       54950.56198803, 59139.6253285 ,  7123.50868077, 53297.12775811,\n",
       "       54967.0875512 , 51882.80424799, 58352.71445338, 68563.45991134,\n",
       "       67419.74779442, 74103.1632785 , 60295.65185628, 55979.88033996,\n",
       "        8850.83598047, 50505.5328585 , 50580.49985142, 48594.3713076 ,\n",
       "       57587.09258803, 57626.75461939, 49259.60257533,  7598.8407914 ,\n",
       "        6481.29049925, 52626.53266457,  5924.87918639, 67753.11510692,\n",
       "       54747.02175808,  8307.79558696,  6209.50876509, 69172.61647818,\n",
       "       65460.6824992 ,  5039.01237896, 53687.60206013, 57808.01652147,\n",
       "       60281.48786675, 54201.33657776,  5386.21052123, 53841.83411193,\n",
       "        5602.27768458,  6899.63906144, 61799.49503021, 48488.97885763,\n",
       "       46292.67872869, 55165.69444105, 60902.51957074, 47426.42993053,\n",
       "       62957.0452531 , 60996.63298236, 56664.27256877, 64700.57144071,\n",
       "       69594.93356504, 49113.20327795, 10172.16686479,  5795.83930652,\n",
       "       58264.83573956, 43180.28131261,  7043.47728841, 83433.83222902,\n",
       "        5463.18807523,  8864.89436013, 45835.89980769, 50550.02904396,\n",
       "        3903.65529255,  6190.96506192,  5537.53754362, 53809.83423849,\n",
       "        5445.89816239,  2822.21615367, 43323.04341035, 44041.21078226,\n",
       "       64555.91392448, 54202.18628823, 59449.21366533, 48341.60127324,\n",
       "       62556.56336038, 63379.46828608, 66349.70262279, 58267.45229482,\n",
       "       55408.05751231, 54738.06062932, 49439.72565696,  7234.68896481,\n",
       "       64955.76277475, 48898.75971839,  5628.81941565,  5172.25076172,\n",
       "       54544.44563564,  7989.8657525 , 53141.96694843, 79421.06742783,\n",
       "       53165.80232469, 56943.718765  , 52085.27953363,  6067.19680583,\n",
       "        6402.15461818, 11883.87398164, 53484.04861128, 56659.20022663,\n",
       "       53565.76158915, 63555.04808211, 46539.62062312,  5281.21704394,\n",
       "       57793.29020494, 59501.16952558, 59092.95897252, 62858.20988336,\n",
       "       50048.13947655, 54743.53536397,  7285.64681866, 62752.85321982,\n",
       "        6852.04945891, 47554.4533788 , 56220.79518419, 56239.26003711,\n",
       "       51371.85552985, 57035.27899787, 55180.26655538, 65978.62017412,\n",
       "       44665.00376147, 55400.16927059, 54414.33290528,  4947.61571502,\n",
       "        8937.25107058, 58628.46506211, 54435.58214755, 52007.63820766,\n",
       "       47657.03239891, 76040.23393851,  5150.22787744,  3839.65735149,\n",
       "        8063.62886285])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(K_test_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "277e0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_train_pet_diag = np.diag(K_train_pet)\n",
    "K_test_pet_diag = np.diag(K_test_pet)\n",
    "            \n",
    "            # Normalize training kernels\n",
    "K_train_pet1 = normalize_kernel(K_train_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55640900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.38815795, 0.96780749, ..., 0.97488157, 0.98813771,\n",
       "        0.96056614],\n",
       "       [0.38815795, 1.        , 0.26398813, ..., 0.30339519, 0.37121304,\n",
       "        0.34413121],\n",
       "       [0.96780749, 0.26398813, 1.        , ..., 0.97141074, 0.9692019 ,\n",
       "        0.9468508 ],\n",
       "       ...,\n",
       "       [0.97488157, 0.30339519, 0.97141074, ..., 1.        , 0.96987121,\n",
       "        0.94176975],\n",
       "       [0.98813771, 0.37121304, 0.9692019 , ..., 0.96987121, 1.        ,\n",
       "        0.96790832],\n",
       "       [0.96056614, 0.34413121, 0.9468508 , ..., 0.94176975, 0.96790832,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_train_pet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e068aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test_pet1 = normalize_test_kernel(K_test_pet, K_train_pet_diag, K_test_pet_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1df7b072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(K_test_pet1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a10351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97820851, 0.3317249 , 0.96994668, ..., 0.98055248, 0.97268604,\n",
       "        0.94933552],\n",
       "       [2.86852876, 1.05714049, 2.8167072 , ..., 2.82620162, 2.88017943,\n",
       "        2.82521268],\n",
       "       [1.10149759, 0.40520653, 1.08220177, ..., 1.08380131, 1.1032387 ,\n",
       "        1.0714366 ],\n",
       "       ...,\n",
       "       [3.2570079 , 1.12964066, 3.22285552, ..., 3.21823629, 3.24593319,\n",
       "        3.16603884],\n",
       "       [3.22036619, 1.0426574 , 3.23536917, ..., 3.20918421, 3.25260393,\n",
       "        3.21594887],\n",
       "       [2.90497471, 1.10449145, 2.83599616, ..., 2.84750803, 2.91375467,\n",
       "        2.84174704]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_test_pet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf83d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
